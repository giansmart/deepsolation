# Experimento 2: DCNN con GroupKFold y Approach por Matriz Completa

## ğŸ¯ Objetivo

Implementar entrenamiento de DCNN para detecciÃ³n de daÃ±o en aisladores sÃ­smicos utilizando un **approach diferente** donde cada muestra representa una matriz completa de frecuencias por sensor, empleando GroupKFold por especÃ­menes fÃ­sicos para obtener mÃ©tricas de rendimiento confiables.

## ğŸ”¬ MetodologÃ­a

### Diferencias Principales vs Exp1

| Aspecto | Exp1 | Exp2 |
|---------|------|------|
| **Estructura de datos** | Una muestra por componente de frecuencia | Una muestra por matriz completa (specimen-sensor) |
| **NÃºmero de muestras** | ~635K registros | ~68 muestras |
| **Balanceo** | SMOTE sobre-sampling | DistribuciÃ³n natural + class weights |
| **Cross-validation** | StratifiedKFold | GroupKFold por specimen fÃ­sico |
| **Splits** | Random por registro | Agrupa A1, A1-2, A1-3 â†’ 'A1' |
| **Enfoque metodolÃ³gico** | Por componente individual | Por matriz completa Yu et al. (2018) |

### Approach de Datos de Exp2

```mermaid
graph TB
    A[Aislador A1 fÃ­sico] --> B[A1: Experimento base]
    A --> C[A1-2: Experimento repeticiÃ³n]
    A --> D[A1-3: Experimento repeticiÃ³n]
    
    E[Exp1: Muestras por componente frecuencia]
    F[Exp2: Muestras por matriz completa]
    
    B --> E
    C --> E  
    D --> E
    
    B --> F
    C --> F
    D --> F
    
    E --> G[635K muestras: cada freq component]
    G --> H[StratifiedKFold aleatorio]
    
    F --> I[68 muestras: matrices completas]
    I --> J[GroupKFold por specimen fÃ­sico]
```

## ğŸ“ Estructura del Experimento

```
src/exp2/
â”œâ”€â”€ README.md                           # Esta documentaciÃ³n
â”œâ”€â”€ 1_preprocess_signals.py             # Preprocesamiento SIN SMOTE
â”œâ”€â”€ 2_train_dcnn.py                     # Training con GroupKFold
â”œâ”€â”€ dcnn_model.py                       # Arquitectura DCNN (copiada de exp1)
â”œâ”€â”€ signal_preprocessing.py             # Utilidades preprocessing (copiada de exp1)
â”œâ”€â”€ models/                             # Modelos entrenados
â”‚   â”œâ”€â”€ dcnn_model_YYYYMMDD_HHMMSS.pth
â”‚   â””â”€â”€ dcnn_model_current.pth
â””â”€â”€ results/                            # Resultados del experimento
    â”œâ”€â”€ preprocessed_dataset.csv        # Dataset sin SMOTE
    â”œâ”€â”€ preprocessed_dataset_summary.txt
    â”œâ”€â”€ exp2_groupkfold_results_YYYYMMDD_HHMMSS.json
    â””â”€â”€ exp2_groupkfold_report_YYYYMMDD_HHMMSS.txt
```

## ğŸ—ï¸ Arquitectura DCNN

### Yu et al. (2018) - Deep Convolutional Neural Network

```mermaid
graph TB
    A[Input: Frequency Domain Features<br/>Shape: batch Ã— freq_components Ã— 3_sensors] --> B[Transpose: batch Ã— 3_sensors Ã— freq_components]
    
    B --> C[Conv1D Layer 1<br/>Filters: 128, Kernel: ~100<br/>Capture large periodicities]
    C --> D[BatchNorm1d + ReLU + MaxPool1d<br/>Pool size: 3, stride: 2]
    D --> E[Dropout: 0.3]
    
    E --> F[Conv1D Layer 2<br/>Filters: 256, Kernel: 30<br/>Medium-scale patterns]
    F --> G[BatchNorm1d + ReLU + MaxPool1d<br/>Pool size: 3, stride: 2]
    G --> H[Dropout: 0.3]
    
    H --> I[Conv1D Layer 3<br/>Filters: 512, Kernel: 10<br/>Fine-scale features]
    I --> J[BatchNorm1d + ReLU + MaxPool1d<br/>Pool size: 3, stride: 2]
    J --> K[Dropout: 0.3]
    
    K --> L[Flatten<br/>Convert to 1D vector]
    
    L --> M[Dense Layer 1<br/>Units: 1024]
    M --> N[BatchNorm1d + ReLU + Dropout: 0.3]
    
    N --> O[Dense Layer 2<br/>Units: 512]
    O --> P[BatchNorm1d + ReLU + Dropout: 0.3]
    
    P --> Q[Output Layer<br/>Units: 3 classes N1, N2, N3]
    Q --> R[Log Softmax<br/>Final probabilities]
    
    style A fill:#e1f5fe
    style R fill:#c8e6c9
    style C fill:#fff3e0
    style F fill:#fff3e0
    style I fill:#fff3e0
    style M fill:#f3e5f5
    style O fill:#f3e5f5
```

### CaracterÃ­sticas Clave de la Arquitectura

- **Multi-scale feature extraction**: Kernels de diferentes tamaÃ±os (100â†’30â†’10)
- **Hierarchical learning**: 128â†’256â†’512 filtros progresivos
- **RegularizaciÃ³n robusta**: BatchNorm + Dropout en cada capa
- **OptimizaciÃ³n estable**: Adaptive pooling y padding='same'

## ğŸ”§ ConfiguraciÃ³n

### HiperparÃ¡metros (IdÃ©nticos a Exp1)

```python
config = {
    "n_splits": 5,           # GroupKFold cross-validation
    "batch_size": 50,        # Yu et al. (2018) optimal
    "learning_rate": 0.0035, # Yu et al. (2018) optimal  
    "epochs": 60,            # Mismo que exp1
    "patience": 15,          # Early stopping
    "dropout_rate": 0.3,     # RegularizaciÃ³n
    "use_class_weights": True # Para manejar desbalance natural
}
```

### DistribuciÃ³n Natural de Clases

```
Total: 635,936 observaciones
- N1 (DaÃ±o mÃ­nimo): 333,051 (52.4%)
- N2 (DaÃ±o medio):  233,172 (36.7%) 
- N3 (DaÃ±o severo):  69,713 (11.0%)
```

## ğŸš€ EjecuciÃ³n

### 1. Preprocesamiento de SeÃ±ales

```bash
cd /path/to/deepsolation
python src/exp2/1_preprocess_signals.py --input-dir data/Signals_Raw --output-file src/exp2/results/preprocessed_dataset.csv
```

**CaracterÃ­sticas:**
- âœ… Sin SMOTE (preserva distribuciÃ³n natural)
- âœ… FFT + PSD segÃºn Yu et al. (2018)
- âœ… Threshold energÃ­a 0.7 para selecciÃ³n de componentes
- âœ… Export con metadatos para GroupKFold

### 2. Entrenamiento con GroupKFold

```bash
cd /path/to/deepsolation
python src/exp2/2_train_dcnn.py --input src/exp2/results/preprocessed_dataset.csv
```

**CaracterÃ­sticas del entrenamiento:**
- âœ… 5-fold GroupKFold por especÃ­menes fÃ­sicos
- âœ… Class weights para manejar desbalance natural
- âœ… Sin data leakage entre aisladores fÃ­sicos
- âœ… Early stopping con patience=15
- âœ… Modelo final entrenado con todos los datos

## ğŸ“Š Ventajas de este Approach

### ğŸ¯ MetodolÃ³gicas

1. **Approach por Matriz Completa**: Cada muestra representa toda la informaciÃ³n frecuencial de un sensor
2. **GroupKFold**: El mismo aislador fÃ­sico nunca estÃ¡ en train y validation simultÃ¡neamente
3. **EvaluaciÃ³n por Aislador**: Las mÃ©tricas reflejan la capacidad de generalizaciÃ³n a nuevos aisladores
4. **DistribuciÃ³n Natural**: Preserva el desbalance real del dominio del problema
5. **Class Weights**: Maneja el desbalance sin generar datos sintÃ©ticos

### ğŸ“ˆ Experimentales

1. **Comparabilidad**: HiperparÃ¡metros idÃ©nticos a exp1 para comparaciÃ³n justa
2. **Reproducibilidad**: Semilla aleatoria fija y metodologÃ­a documentada
3. **Trazabilidad**: Reportes detallados de grupos en cada fold
4. **Robustez**: Cross-validation con mÃºltiples folds para estabilidad

## ğŸ” AnÃ¡lisis de Resultados

### MÃ©tricas Reportadas

- **Accuracy promedio**: Media Â± desviaciÃ³n estÃ¡ndar cross-validation
- **Accuracy por fold**: Resultados individuales de cada fold
- **Grupos por fold**: QuÃ© especÃ­menes fÃ­sicos en train/val
- **Tiempo de entrenamiento**: Por fold y total
- **DetecciÃ³n de leakage**: VerificaciÃ³n automÃ¡tica sin overlapping

### InterpretaciÃ³n

Las mÃ©tricas de exp2 serÃ¡n **diferentes** a exp1 debido al approach distinto:

- ğŸ“Š **Diferentes magnitudes**: Debido al nÃºmero diferente de muestras
- ğŸ“Š **Enfoque por aislador**: EvalÃºa generalizaciÃ³n a nivel de aislador completo  
- ğŸ“Š **MÃ©tricas estables**: GroupKFold proporciona evaluaciÃ³n mÃ¡s robusta
- ğŸ“Š **DistribuciÃ³n natural**: Refleja el desbalance real del problema

## ğŸ“š Referencias TÃ©cnicas

### Conceptos Clave

- **Approach por Matriz**: Una muestra = matriz completa de frecuencias por sensor
- **GroupKFold**: Cross-validation respetando grupos relacionados (especÃ­menes fÃ­sicos)
- **Class Weights**: Manejo de desbalance sin sobre-sampling artificial
- **Yu et al. (2018)**: MetodologÃ­a base FFT + PSD + DCNN

### Papers Relacionados

1. **Yu et al. (2018)**: "Deep learning for structural damage identification"
2. **Cawley & Talbot (2010)**: "On Over-fitting in Model Selection"  
3. **Kaufman et al. (2012)**: "Leakage in Data Mining: Formulation, Detection"

## âš ï¸ Consideraciones Importantes

### Limitaciones

1. **Menor accuracy**: Esperado vs exp1 debido a eliminaciÃ³n de leakage
2. **Dataset pequeÃ±o**: Solo 34 especÃ­menes fÃ­sicos para cross-validation
3. **Desbalance natural**: N3 solo 11% de los datos

### Recomendaciones

1. **Aumentar dataset**: MÃ¡s especÃ­menes fÃ­sicos para mejor generalizaciÃ³n
2. **TÃ©cnicas avanzadas**: Focal loss, ensemble methods para desbalance  
3. **Feature engineering**: AnÃ¡lisis de componentes principales, etc.

## ğŸ¯ ComparaciÃ³n Experimental

| MÃ©trica | Exp1 (Con Leakage) | Exp2 (Sin Leakage) | Diferencia |
|---------|---------------------|---------------------|-------------|
| Test Accuracy | X.XXXX | Y.YYYY | â†“ Z.ZZ% |
| Realismo | âŒ Optimista | âœ… Realista | N/A |
| Confiabilidad | âŒ Sesgada | âœ… VÃ¡lida | N/A |
| GeneralizaciÃ³n | âŒ Dudosa | âœ… Demostrada | N/A |

---

**ğŸ ConclusiÃ³n**: Exp2 proporciona un approach alternativo basado en matrices completas por sensor, utilizando GroupKFold para evaluar la capacidad del modelo DCNN de generalizar a nuevos aisladores sÃ­smicos no vistos durante el entrenamiento.