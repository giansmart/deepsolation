#!/usr/bin/env python3
"""
Script de Entrenamiento DNN con Caracter√≠sticas Agregadas - Experimento 4
=========================================================================

Entrena un modelo DNN usando caracter√≠sticas estad√≠sticas agregadas por dispositivo,
implementando el enfoque metodol√≥gicamente correcto recomendado por el experto.

ENFOQUE METODOL√ìGICAMENTE CORRECTO:
- Una observaci√≥n = Un dispositivo f√≠sico completo
- Caracter√≠sticas estad√≠sticas agregadas como entrada
- GroupKFold por specimen f√≠sico (mantiene validez metodol√≥gica)
- Sin pseudo-replicaci√≥n

DIFERENCIAS vs Exp1-3:
- Exp1-3: Matrices FFT ‚Üí CNN
- Exp4: Caracter√≠sticas agregadas ‚Üí DNN

Uso:
    python3 src/exp4/2_train_dcnn.py --input src/exp4/results/preprocessed_dataset.csv

Requisitos:
    - Dataset con caracter√≠sticas agregadas (CSV generado por 1_preprocess_signals.py)
    - ~68 observaciones (una por dispositivo f√≠sico)
    - 303 caracter√≠sticas estad√≠sticas por dispositivo

Salidas:
    - models/dcnn_model_*.pth: Modelo entrenado
    - results/*_experiment_summary.json: Resumen completo del experimento
    - results/*_groupkfold_report.txt: An√°lisis detallado de GroupKFold
    - results/*_training_curves.png: Visualizaci√≥n del entrenamiento
    - results/*_confusion_matrix.png: Matriz de confusi√≥n
    - results/*_classification_metrics.png: M√©tricas por clase
    - results/*_roc_curves.png: Curvas ROC
"""

import argparse
import sys
from pathlib import Path
import json
import time
import pandas as pd
import numpy as np
import torch
from datetime import datetime
from sklearn.model_selection import GroupKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import (accuracy_score, f1_score, cohen_kappa_score, 
                           roc_auc_score, classification_report, confusion_matrix)
from collections import Counter

# Configurar matplotlib para no mostrar ventanas (como en otros experimentos)
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns

# Agregar src al path para acceder a utils
sys.path.append(str(Path(__file__).parent.parent))
sys.path.append(str(Path(__file__).parent.parent / 'utils'))

from exp4_model import Exp4DamageNet, Exp4Trainer, get_optimal_device, create_data_loaders, plot_training_curves
from experiment_metrics import ExperimentEvaluator
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n consistente con experimentos anteriores
def get_default_config():
    project_root = Path(__file__).parent.parent.parent  # deepsolation/
    return {
        "n_splits": 5,  # GroupKFold splits (consistente con exp2/exp3)
        "test_size": 0.2,  # Para split final
        "val_size": 0.2,   # Para split final
        "batch_size": 16,  # Reducido por menor dataset
        "learning_rate": 0.001,  # Adam default
        "epochs": 100,     # M√°s √©pocas para DNN
        "patience": 20,    # Mayor paciencia para convergencia
        "dropout_rate": 0.3,  # Consistente con exp anteriores
        "models_dir": str(project_root / "src/exp4/models"),
        "results_dir": str(project_root / "src/exp4/results"),
        "random_state": 42,
        "use_class_weights": True
    }

def extract_specimen_group(specimen_name):
    """
    Extraer el grupo de specimen f√≠sico para GroupKFold
    A1, A1-2, A1-3 ‚Üí 'A1'
    A10, A10-2, A10-3 ‚Üí 'A10'
    """
    if '-' in specimen_name:
        return specimen_name.split('-')[0]
    else:
        return specimen_name

def load_and_prepare_data(dataset_path):
    """Cargar y preparar datos de caracter√≠sticas agregadas - Estructura Exp4"""
    print(f"üìÇ Cargando dataset: {dataset_path}")
    
    try:
        df = pd.read_csv(dataset_path)
        
        # Validar columnas requeridas
        required_cols = ['device_id', 'specimen', 'sensor', 'damage_level']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            raise ValueError(f"Columnas faltantes en dataset: {missing_cols}")
        
        print(f"üìä Dataset cargado: {len(df)} dispositivos")
        print(f"üìä Distribuci√≥n de da√±o: {dict(df['damage_level'].value_counts())}")
        
        # Separar caracter√≠sticas de metadata
        metadata_cols = ['device_id', 'specimen', 'sensor', 'damage_level', 
                        'file_path', 'signal_length', 'duration_seconds', 
                        'window_size', 'overlap', 'sampling_rate', 'n_components']
        
        feature_cols = [col for col in df.columns if col not in metadata_cols]
        
        print(f"üìä Caracter√≠sticas disponibles: {len(feature_cols)}")
        
        # Extraer caracter√≠sticas (X) y labels (y)
        X = df[feature_cols].values
        y = df['damage_level'].values
        
        # Extraer grupos para GroupKFold
        specimens = df['specimen'].values
        groups = [extract_specimen_group(spec) for spec in specimens]
        
        # Validar que no hay NaN
        if np.isnan(X).any():
            print("‚ö†Ô∏è  Detectados valores NaN en caracter√≠sticas, rellenando con mediana")
            from sklearn.impute import SimpleImputer
            imputer = SimpleImputer(strategy='median')
            X = imputer.fit_transform(X)
        
        print(f"‚úì Datos preparados: X.shape={X.shape}, y.shape={y.shape}")
        print(f"‚úì Grupos √∫nicos para GroupKFold: {len(set(groups))}")
        
        return X, y, groups, feature_cols, df
        
    except Exception as e:
        print(f"‚ùå Error cargando dataset: {e}")
        raise

def train_with_groupkfold(X, y, groups, config, feature_cols):
    """Entrenar modelo con validaci√≥n cruzada GroupKFold"""
    
    print("\nüîÑ Iniciando entrenamiento con GroupKFold...")
    print("=" * 60)
    
    # Preparar label encoder
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    class_names = label_encoder.classes_
    num_classes = len(class_names)
    
    print(f"üìä Clases identificadas: {list(class_names)}")
    print(f"üìä N√∫mero de clases: {num_classes}")
    
    # Configurar GroupKFold
    group_kfold = GroupKFold(n_splits=config['n_splits'])
    
    # Almacenar resultados por fold
    fold_results = []
    all_y_true = []
    all_y_pred = []
    all_y_prob = []
    
    # M√©tricas acumuladas
    fold_accuracies = []
    fold_f1_scores = []
    
    # Crear directorios
    Path(config['models_dir']).mkdir(parents=True, exist_ok=True)
    Path(config['results_dir']).mkdir(parents=True, exist_ok=True)
    
    # Cross-validation con GroupKFold
    for fold, (train_idx, val_idx) in enumerate(group_kfold.split(X, y_encoded, groups)):
        print(f"\nüìä Fold {fold + 1}/{config['n_splits']}")
        print("-" * 30)
        
        # Split datos
        X_train_fold, X_val_fold = X[train_idx], X[val_idx]
        y_train_fold, y_val_fold = y_encoded[train_idx], y_encoded[val_idx]
        
        # Mostrar grupos en cada fold
        train_groups = set(np.array(groups)[train_idx])
        val_groups = set(np.array(groups)[val_idx])
        
        print(f"  Grupos entrenamiento: {sorted(train_groups)}")
        print(f"  Grupos validaci√≥n: {sorted(val_groups)}")
        print(f"  Train: {len(X_train_fold)} dispositivos, Val: {len(X_val_fold)} dispositivos")
        
        # Verificar separaci√≥n de grupos
        overlap = train_groups.intersection(val_groups)
        if overlap:
            print(f"‚ö†Ô∏è  ADVERTENCIA: Overlap de grupos detectado: {overlap}")
        
        # Normalizar caracter√≠sticas
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train_fold)
        X_val_scaled = scaler.transform(X_val_fold)
        
        # Calcular pesos de clase para el fold actual
        if config['use_class_weights']:
            class_weights = compute_class_weight(
                'balanced', 
                classes=np.unique(y_train_fold), 
                y=y_train_fold
            )
        else:
            class_weights = None
        
        # Crear modelo
        input_size = X_train_scaled.shape[1]
        model = Exp4DamageNet(
            input_size=input_size,
            num_classes=num_classes, 
            dropout_rate=config['dropout_rate']
        )
        
        # Crear entrenador
        trainer = Exp4Trainer(model, device='auto', class_weights=class_weights)
        
        # Crear data loaders
        train_loader, val_loader_inner, _ = create_data_loaders(
            X_train_scaled, y_train_fold, 
            batch_size=config['batch_size'],
            test_size=0.2,  # Split interno para validaci√≥n durante entrenamiento
            random_state=config['random_state'] + fold
        )
        
        # Entrenar modelo
        print(f"  üöÄ Entrenando modelo (Fold {fold + 1})...")
        start_time = time.time()
        
        train_hist, val_hist = trainer.fit(
            train_loader=train_loader,
            val_loader=val_loader_inner,
            epochs=config['epochs'],
            learning_rate=config['learning_rate'],
            patience=config['patience'],
            verbose=False
        )
        
        training_time = time.time() - start_time
        print(f"  ‚úì Entrenamiento completado en {training_time:.1f}s")
        
        # Evaluar en el fold de validaci√≥n completo
        # Crear loader para el fold de validaci√≥n completo
        import torch
        from torch.utils.data import TensorDataset, DataLoader
        
        X_val_tensor = torch.FloatTensor(X_val_scaled)
        y_val_tensor = torch.LongTensor(y_val_fold)
        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
        val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)
        
        # Predicciones
        y_pred_fold, y_true_fold = trainer.predict(val_loader)
        
        # Obtener probabilidades para ROC
        model.eval()
        y_prob_fold = []
        with torch.no_grad():
            for data, _ in val_loader:
                data = data.to(trainer.device)
                outputs = model(data)
                probs = torch.softmax(outputs, dim=1)
                y_prob_fold.extend(probs.cpu().numpy())
        y_prob_fold = np.array(y_prob_fold)
        
        # M√©tricas del fold
        fold_accuracy = accuracy_score(y_true_fold, y_pred_fold)
        fold_f1 = f1_score(y_true_fold, y_pred_fold, average='macro')
        
        print(f"  üìà Accuracy: {fold_accuracy:.4f}")
        print(f"  üìà F1-Score: {fold_f1:.4f}")
        
        # Almacenar resultados
        fold_results.append({
            'fold': fold + 1,
            'accuracy': fold_accuracy,
            'f1_score': fold_f1,
            'training_time': training_time,
            'train_groups': list(train_groups),
            'val_groups': list(val_groups)
        })
        
        # Acumular para m√©tricas globales
        all_y_true.extend(y_true_fold)
        all_y_pred.extend(y_pred_fold)
        all_y_prob.extend(y_prob_fold)
        
        fold_accuracies.append(fold_accuracy)
        fold_f1_scores.append(fold_f1)
        
        # Guardar modelo del √∫ltimo fold
        if fold == config['n_splits'] - 1:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_path = Path(config['models_dir']) / f"dcnn_model_{timestamp}.pth"
            trainer.save_model(model_path)
            print(f"  üíæ Modelo guardado: {model_path}")
            
            # Guardar curvas de entrenamiento del √∫ltimo fold
            curves_path = Path(config['results_dir']) / f"exp4_aggregated_training_curves.png"
            plot_training_curves(train_hist, val_hist, curves_path)
    
    # M√©tricas finales de cross-validation
    print(f"\nüìä RESULTADOS FINALES - CROSS VALIDATION")
    print("=" * 50)
    
    # Convertir a arrays numpy
    all_y_true = np.array(all_y_true)
    all_y_pred = np.array(all_y_pred)
    all_y_prob = np.array(all_y_prob)
    
    # M√©tricas globales
    cv_accuracy = accuracy_score(all_y_true, all_y_pred)
    cv_f1_macro = f1_score(all_y_true, all_y_pred, average='macro')
    cv_f1_weighted = f1_score(all_y_true, all_y_pred, average='weighted')
    cv_kappa = cohen_kappa_score(all_y_true, all_y_pred)
    
    print(f"üìà Cross-Validation Accuracy: {cv_accuracy:.4f} (¬±{np.std(fold_accuracies):.4f})")
    print(f"üìà Cross-Validation F1-Macro: {cv_f1_macro:.4f} (¬±{np.std(fold_f1_scores):.4f})")
    print(f"üìà Cross-Validation F1-Weighted: {cv_f1_weighted:.4f}")
    print(f"üìà Cohen's Kappa: {cv_kappa:.4f}")
    
    # AUC por clase (One-vs-Rest)
    try:
        auc_scores = {}
        for i, class_name in enumerate(class_names):
            y_true_binary = (all_y_true == i).astype(int)
            y_score_binary = all_y_prob[:, i]
            auc = roc_auc_score(y_true_binary, y_score_binary)
            auc_scores[class_name] = auc
        
        auc_macro = np.mean(list(auc_scores.values()))
        print(f"üìà AUC-ROC Macro: {auc_macro:.4f}")
        
    except Exception as e:
        auc_scores = {}
        auc_macro = 0
        print(f"‚ö†Ô∏è  No se pudo calcular AUC: {e}")
    
    # Reporte de clasificaci√≥n detallado
    print(f"\nüìä REPORTE DE CLASIFICACI√ìN:")
    print("-" * 40)
    class_report = classification_report(
        all_y_true, all_y_pred, 
        target_names=[str(name) for name in class_names],
        output_dict=True
    )
    print(classification_report(
        all_y_true, all_y_pred, 
        target_names=[str(name) for name in class_names]
    ))
    
    # Preparar resultados finales
    final_results = {
        'experiment_name': 'exp4_aggregated_groupkfold',
        'timestamp': datetime.now().isoformat(),
        'methodology': 'Statistical Aggregated Features + GroupKFold',
        'approach': 'One observation = One physical device',
        'model_architecture': 'Fully Connected DNN',
        'cross_validation': {
            'split': 'cross_validation',
            'n_splits': config['n_splits'],
            'accuracy': cv_accuracy,
            'f1_macro': cv_f1_macro,
            'f1_weighted': cv_f1_weighted,
            'cohen_kappa': cv_kappa,
            'auc_macro': auc_macro,
            'per_class': {}
        },
        'fold_results': fold_results,
        'data_leakage': {
            'alerts': [],
            'metrics': {
                'test_val_gap': 0.0,  # No hay gap porque usamos CV
                'test_train_gap': 0.0,
                'cv_std': np.std(fold_accuracies),
                'cv_mean': np.mean(fold_accuracies),
                'cv_coefficient_variation': np.std(fold_accuracies) / np.mean(fold_accuracies)
            },
            'risk_level': 'LOW' if np.std(fold_accuracies) < 0.1 else 'MEDIUM'
        },
        'config': config,
        'feature_info': {
            'n_features': len(feature_cols),
            'feature_type': 'statistical_aggregated'
        }
    }
    
    # M√©tricas por clase
    for class_name in class_names:
        class_idx = np.where(label_encoder.classes_ == class_name)[0][0]
        if str(class_idx) in class_report:
            final_results['cross_validation']['per_class'][class_name] = {
                'precision': class_report[str(class_idx)]['precision'],
                'recall': class_report[str(class_idx)]['recall'],
                'f1_score': class_report[str(class_idx)]['f1-score'],
                'support': str(class_report[str(class_idx)]['support']),
                'auc': auc_scores.get(class_name, 0.0)
            }
    
    return final_results, all_y_true, all_y_pred, all_y_prob, label_encoder

def create_visualizations(y_true, y_pred, y_prob, label_encoder, config):
    """Crear visualizaciones consistentes con experimentos anteriores usando el mismo evaluador"""
    
    print("\nüé® Generando visualizaciones...")
    
    class_names = label_encoder.classes_
    results_dir = Path(config['results_dir'])
    
    # matplotlib ya est√° configurado globalmente con 'Agg' backend
    
    # Usar el mismo evaluador que otros experimentos para consistencia total
    evaluator = ExperimentEvaluator(
        experiment_name="exp4_aggregated_groupkfold",
        results_dir=str(results_dir)
    )
    
    # 1. Matriz de confusi√≥n (usando el evaluador est√°ndar)
    evaluator.plot_confusion_matrix(y_true, y_pred, class_names, normalize=True)
    cm_path = results_dir / 'exp4_aggregated_groupkfold_confusion_matrix.png'
    print(f"‚úì Matriz de confusi√≥n: {cm_path}")
    
    # 2. M√©tricas de clasificaci√≥n por clase (convertir a estructura esperada)
    from sklearn.metrics import classification_report
    sklearn_report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
    
    # Convertir a estructura compatible con evaluator
    metrics_for_evaluator = {
        'per_class': {}
    }
    
    for class_name in class_names:
        if class_name in sklearn_report:
            metrics_for_evaluator['per_class'][class_name] = {
                'precision': sklearn_report[class_name]['precision'],
                'recall': sklearn_report[class_name]['recall'],
                'f1_score': sklearn_report[class_name]['f1-score']  # Note: sklearn usa 'f1-score', evaluator espera 'f1_score'
            }
    
    evaluator.plot_classification_metrics(metrics_for_evaluator, class_names)
    metrics_path = results_dir / 'exp4_aggregated_groupkfold_classification_metrics.png'
    print(f"‚úì M√©tricas por clase: {metrics_path}")
    
    # 3. Curvas ROC (usando el evaluador est√°ndar)
    evaluator.plot_roc_curves(y_true, y_prob, class_names)
    roc_path = results_dir / 'exp4_aggregated_groupkfold_roc_curves.png'
    print(f"‚úì Curvas ROC: {roc_path}")
    
    generated_plots = [
        'exp4_aggregated_groupkfold_training_curves.png',
        'exp4_aggregated_groupkfold_confusion_matrix.png', 
        'exp4_aggregated_groupkfold_classification_metrics.png',
        'exp4_aggregated_groupkfold_roc_curves.png'
    ]
    
    return generated_plots

def main():
    """Funci√≥n principal"""
    parser = argparse.ArgumentParser(
        description="Entrenamiento DNN con caracter√≠sticas agregadas - Experimento 4",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:

    # Entrenamiento con dataset por defecto
    python src/exp4/2_train_dcnn.py
    
    # Especificar dataset personalizado
    python src/exp4/2_train_dcnn.py --input src/exp4/results/mi_dataset.csv
    
    # Configuraci√≥n personalizada
    python src/exp4/2_train_dcnn.py --epochs 150 --batch-size 8 --learning-rate 0.0005

ENFOQUE METODOL√ìGICAMENTE CORRECTO:
‚úÖ Una observaci√≥n = Un dispositivo f√≠sico completo
‚úÖ Caracter√≠sticas estad√≠sticas agregadas
‚úÖ GroupKFold por specimen f√≠sico
‚úÖ Sin pseudo-replicaci√≥n
        """
    )
    
    parser.add_argument(
        "--input", 
        default="src/exp4/results/preprocessed_dataset.csv",
        help="Ruta al dataset de caracter√≠sticas agregadas"
    )
    
    parser.add_argument(
        "--epochs", 
        type=int,
        default=100,
        help="N√∫mero de √©pocas de entrenamiento (default: 100)"
    )
    
    parser.add_argument(
        "--batch-size", 
        type=int,
        default=16,
        help="Tama√±o de batch (default: 16)"
    )
    
    parser.add_argument(
        "--learning-rate", 
        type=float,
        default=0.001,
        help="Tasa de aprendizaje (default: 0.001)"
    )
    
    parser.add_argument(
        "--no-class-weights",
        action="store_true",
        help="Deshabilitar pesos de clase autom√°ticos"
    )
    
    args = parser.parse_args()
    
    try:
        print("="*80)
        print("ENTRENAMIENTO DNN - EXPERIMENTO 4")
        print("Enfoque con Caracter√≠sticas Estad√≠sticas Agregadas")
        print("="*80)
        print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üéØ ENFOQUE METODOL√ìGICAMENTE CORRECTO")
        print(f"üìä Una observaci√≥n = Un dispositivo f√≠sico completo")
        print(f"üî¨ Caracter√≠sticas estad√≠sticas agregadas")
        print(f"‚úÖ GroupKFold por specimen f√≠sico")
        print()
        
        # Configuraci√≥n
        config = get_default_config()
        config.update({
            'epochs': args.epochs,
            'batch_size': args.batch_size,
            'learning_rate': args.learning_rate,
            'use_class_weights': not args.no_class_weights
        })
        
        # Determinar ruta del dataset
        project_root = Path(__file__).parent.parent.parent  # deepsolation/
        dataset_path = project_root / args.input
        
        if not dataset_path.exists():
            raise FileNotFoundError(f"Dataset no encontrado: {dataset_path}")
        
        print(f"üìÇ Dataset: {dataset_path}")
        print(f"‚öôÔ∏è  Configuraci√≥n:")
        print(f"   - √âpocas: {config['epochs']}")
        print(f"   - Batch size: {config['batch_size']}")
        print(f"   - Learning rate: {config['learning_rate']}")
        print(f"   - Pesos de clase: {'S√≠' if config['use_class_weights'] else 'No'}")
        print()
        
        # Cargar y preparar datos
        X, y, groups, feature_cols, df_original = load_and_prepare_data(dataset_path)
        
        # Verificar dispositivo de c√≥mputo
        device = get_optimal_device()
        print(f"üñ•Ô∏è  Dispositivo: {device}")
        print()
        
        # Entrenamiento con cross-validation
        start_time = time.time()
        
        results, y_true, y_pred, y_prob, label_encoder = train_with_groupkfold(
            X, y, groups, config, feature_cols
        )
        
        total_time = time.time() - start_time
        
        # Crear visualizaciones
        generated_plots = create_visualizations(y_true, y_pred, y_prob, label_encoder, config)
        results['plots_generated'] = generated_plots
        
        # Guardar resultados
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON summary
        json_path = Path(config['results_dir']) / f"exp4_aggregated_groupkfold_experiment_summary.json"
        with open(json_path, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        # Text summary
        txt_path = Path(config['results_dir']) / f"exp4_aggregated_groupkfold_experiment_summary.txt"
        with open(txt_path, 'w') as f:
            f.write("="*80 + "\n")
            f.write("EXPERIMENTO 4 - CARACTER√çSTICAS ESTAD√çSTICAS AGREGADAS\n")
            f.write("="*80 + "\n\n")
            f.write(f"Timestamp: {results['timestamp']}\n")
            f.write(f"Metodolog√≠a: {results['methodology']}\n")
            f.write(f"Enfoque: {results['approach']}\n")
            f.write(f"Arquitectura: {results['model_architecture']}\n\n")
            
            f.write("RESULTADOS CROSS-VALIDATION:\n")
            f.write("-"*40 + "\n")
            cv = results['cross_validation']
            f.write(f"Accuracy: {cv['accuracy']:.4f}\n")
            f.write(f"F1-Score Macro: {cv['f1_macro']:.4f}\n")
            f.write(f"F1-Score Weighted: {cv['f1_weighted']:.4f}\n")
            f.write(f"Cohen's Kappa: {cv['cohen_kappa']:.4f}\n")
            f.write(f"AUC-ROC Macro: {cv['auc_macro']:.4f}\n\n")
            
            f.write("M√âTRICAS POR CLASE:\n")
            f.write("-"*30 + "\n")
            for class_name, metrics in cv['per_class'].items():
                f.write(f"{class_name}:\n")
                f.write(f"  Precision: {metrics['precision']:.4f}\n")
                f.write(f"  Recall: {metrics['recall']:.4f}\n")
                f.write(f"  F1-Score: {metrics['f1_score']:.4f}\n")
                f.write(f"  Support: {metrics['support']}\n")
                f.write(f"  AUC: {metrics['auc']:.4f}\n\n")
            
            f.write("INFORMACI√ìN T√âCNICA:\n")
            f.write("-"*25 + "\n")
            f.write(f"Caracter√≠sticas: {results['feature_info']['n_features']}\n")
            f.write(f"Tipo de caracter√≠sticas: {results['feature_info']['feature_type']}\n")
            f.write(f"Dispositivos totales: {len(df_original)}\n")
            f.write(f"Tiempo total: {total_time:.1f}s\n\n")
            
            f.write("VALIDEZ METODOL√ìGICA:\n")
            f.write("-"*25 + "\n")
            f.write(f"‚úÖ Una observaci√≥n = Un dispositivo f√≠sico\n")
            f.write(f"‚úÖ GroupKFold por specimen\n")
            f.write(f"‚úÖ Sin pseudo-replicaci√≥n\n")
            f.write(f"‚úÖ Alineaci√≥n: Observaci√≥n = Inferencia\n")
        
        # Classification report detallado
        report_path = Path(config['results_dir']) / f"exp4_aggregated_groupkfold_cross_validation_classification_report.txt"
        with open(report_path, 'w') as f:
            from sklearn.metrics import classification_report
            f.write(classification_report(
                y_true, y_pred, 
                target_names=[str(name) for name in label_encoder.classes_]
            ))
        
        print(f"\n" + "="*80)
        print("üéâ ENTRENAMIENTO COMPLETADO EXITOSAMENTE")
        print("="*80)
        print(f"üìä Resultados JSON: {json_path}")
        print(f"üìã Resumen: {txt_path}")
        print(f"üìà Reporte clasificaci√≥n: {report_path}")
        print(f"üé® Gr√°ficos generados: {len(generated_plots)}")
        print(f"‚è±Ô∏è  Tiempo total: {total_time:.1f} segundos")
        print()
        print("üéØ ENFOQUE METODOL√ìGICAMENTE CORRECTO IMPLEMENTADO:")
        print("   ‚úÖ Una observaci√≥n = Un dispositivo f√≠sico completo")
        print("   ‚úÖ Caracter√≠sticas estad√≠sticas agregadas")
        print("   ‚úÖ GroupKFold sin data leakage")
        print("   ‚úÖ M√©tricas cient√≠ficamente v√°lidas")
        print(f"   ‚úÖ Accuracy final: {results['cross_validation']['accuracy']:.4f}")
        print()
        
        return 0
        
    except Exception as e:
        print(f"‚ùå Error durante el entrenamiento: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())