#!/usr/bin/env python3
"""
Script de Preprocesamiento de SeÃ±ales - Experimento 4
=====================================================

Implementa el enfoque metodolÃ³gicamente correcto recomendado por el experto:

ENFOQUE CORRECTO - EXP4:
- Una observaciÃ³n = Un dispositivo completo (specimen-sensor)
- Una etiqueta por dispositivo (no bins individuales)
- CaracterÃ­sticas estadÃ­sticas agregadas del espectro
- Ventanas temporales con estadÃ­sticos robustos
- PrevenciÃ³n total de pseudo-replicaciÃ³n

DIFERENCIAS CRÃTICAS vs Exp1-3:
- NO trata bins de frecuencia como observaciones independientes
- Extrae caracterÃ­sticas globales del dispositivo completo
- Alinea unidad de observaciÃ³n con unidad de inferencia
- MetodologÃ­a cientÃ­ficamente vÃ¡lida

Procesamiento:
- AnÃ¡lisis estadÃ­stico temporal por ventanas
- CaracterÃ­sticas espectrales agregadas
- MÃ©tricas de energÃ­a y frecuencia dominante
- EstadÃ­sticos de distribuciÃ³n espectral
- Export con una fila por dispositivo fÃ­sico

Uso:
    python3 src/exp4/1_preprocess_signals.py [--output OUTPUT_PATH]

Salidas:
    - results/preprocessed_dataset.csv: Dataset metodolÃ³gicamente correcto
    - results/preprocessing_summary.txt: Resumen detallado del approach

RESULTADO: Una observaciÃ³n por dispositivo fÃ­sico (~36 observaciones)
"""

import argparse
import sys
from pathlib import Path
import time
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Agregar src al path para acceso a utils
sys.path.append(str(Path(__file__).parent.parent))

from exp4_signal_preprocessing import Exp4SignalPreprocessor

def main():
    """FunciÃ³n principal"""
    parser = argparse.ArgumentParser(
        description="Preprocesamiento metodolÃ³gicamente correcto - Experimento 4",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:

    # Preprocesamiento metodolÃ³gicamente correcto (recomendado)
    python src/exp4/1_preprocess_signals.py
    
    # Especificar archivo de salida
    python src/exp4/1_preprocess_signals.py --output src/exp4/results/dataset_correcto.csv

ENFOQUE METODOLÃ“GICAMENTE CORRECTO:
- Una observaciÃ³n = Un dispositivo completo (no bins individuales)
- CaracterÃ­sticas estadÃ­sticas agregadas
- PrevenciÃ³n total de pseudo-replicaciÃ³n
- AlineaciÃ³n correcta: unidad observaciÃ³n = unidad inferencia
        """
    )
    
    parser.add_argument(
        "--output", 
        default="src/exp4/results/preprocessed_dataset.csv",
        help="Ruta del archivo de salida (default: src/exp4/results/preprocessed_dataset.csv)"
    )
    
    parser.add_argument(
        "--window-size", 
        type=int,
        default=1000,
        help="TamaÃ±o de ventana temporal para anÃ¡lisis estadÃ­stico (default: 1000 samples = 10s @ 100Hz)"
    )
    
    parser.add_argument(
        "--overlap", 
        type=float,
        default=0.5,
        help="Overlap entre ventanas (default: 0.5 = 50%)"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Mostrar informaciÃ³n detallada del proceso"
    )
    
    args = parser.parse_args()
    
    try:
        print("="*80)
        print("PREPROCESAMIENTO METODOLÃ“GICAMENTE CORRECTO - EXPERIMENTO 4")
        print("="*80)
        print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¯ ENFOQUE CORRECTO: Una observaciÃ³n = Un dispositivo completo")
        print(f"ğŸ”¬ MetodologÃ­a: CaracterÃ­sticas estadÃ­sticas agregadas")
        print(f"âœ… PrevenciÃ³n total de pseudo-replicaciÃ³n")
        print(f"ğŸ“Š AlineaciÃ³n correcta: Unidad observaciÃ³n = Unidad inferencia")
        print()
        
        # Determinar archivo de salida
        project_root = Path(__file__).parent.parent.parent  # deepsolation/
        if args.output:
            output_path = project_root / args.output
        else:
            output_path = project_root / "src/exp4/results/preprocessed_dataset.csv"
            
        # Crear directorio de salida si no existe
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Configurar preprocessor
        print(f"ğŸ“‚ Archivo de salida: {output_path}")
        print(f"ğŸªŸ TamaÃ±o de ventana: {args.window_size} samples ({args.window_size/100:.1f}s @ 100Hz)")
        print(f"ğŸ”„ Overlap: {args.overlap*100:.0f}%")
        print()
        
        # Inicializar preprocessor metodolÃ³gicamente correcto
        preprocessor = Exp4SignalPreprocessor(
            sampling_rate=100,
            window_size=args.window_size,
            overlap=args.overlap,
            verbose=args.verbose
        )
        
        # Procesar seÃ±ales
        print("ğŸ”„ Iniciando preprocesamiento metodolÃ³gicamente correcto...")
        start_time = time.time()
        
        # Directorio de seÃ±ales
        signals_dir = project_root / "data" / "Signals_Raw"
        
        if not signals_dir.exists():
            raise FileNotFoundError(f"Directorio de seÃ±ales no encontrado: {signals_dir}")
        
        print(f"ğŸ“ Directorio de seÃ±ales: {signals_dir}")
        
        # Procesar todas las seÃ±ales con enfoque correcto
        processed_data = preprocessor.process_all_signals_correct(
            signals_dir=str(signals_dir),
            output_dir=str(output_path.parent)
        )
        
        processing_time = time.time() - start_time
        print(f"âœ“ Preprocesamiento completado en {processing_time:.1f} segundos")
        
        # Cargar labels para exportaciÃ³n
        labels_path = project_root / "data" / "nivel_damage.csv"
        if not labels_path.exists():
            raise FileNotFoundError(f"Archivo de labels no encontrado: {labels_path}")
        
        import pandas as pd
        labels_df = pd.read_csv(labels_path)
        
        # Exportar a CSV con enfoque metodolÃ³gicamente correcto
        print("ğŸ“¤ Exportando dataset metodolÃ³gicamente correcto...")
        export_start = time.time()
        
        dataset_summary = preprocessor.export_correct_dataset(
            processed_data, 
            labels_df,
            output_path
        )
        
        export_time = time.time() - export_start
        print(f"âœ“ ExportaciÃ³n completada en {export_time:.1f} segundos")
        
        # Generar resumen metodolÃ³gico
        summary_path = output_path.parent / f"{output_path.stem}_summary.txt"
        
        # Analizar dataset generado para resumen
        if output_path.exists():
            dataset_df = pd.read_csv(output_path)
            total_devices = len(dataset_df)
            specimens = dataset_df['specimen'].nunique() if 'specimen' in dataset_df.columns else 0
            damage_dist = dataset_df['damage_level'].value_counts().sort_index() if 'damage_level' in dataset_df.columns else {}
        else:
            total_devices = specimens = 0
            damage_dist = {}
        
        with open(summary_path, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("DATASET METODOLÃ“GICAMENTE CORRECTO - EXPERIMENTO 4\n")
            f.write("Enfoque CientÃ­ficamente VÃ¡lido para ML Estructural\n")
            f.write("=" * 80 + "\n\n")
            f.write(f"Export Date: {datetime.now()}\n")
            f.write(f"MetodologÃ­a: CaracterÃ­sticas estadÃ­sticas agregadas por dispositivo\n")
            f.write(f"PrevenciÃ³n Data Leakage: Enfoque metodolÃ³gicamente correcto\n\n")
            
            f.write("ENFOQUE METODOLÃ“GICAMENTE CORRECTO:\n")
            f.write("-" * 40 + "\n")
            f.write(f"âœ… Una observaciÃ³n = Un dispositivo fÃ­sico completo\n")
            f.write(f"âœ… Una etiqueta por dispositivo (no bins independientes)\n")
            f.write(f"âœ… CaracterÃ­sticas estadÃ­sticas agregadas\n")
            f.write(f"âœ… PrevenciÃ³n total de pseudo-replicaciÃ³n\n")
            f.write(f"âœ… AlineaciÃ³n: Unidad observaciÃ³n = Unidad inferencia\n\n")
            
            f.write("DATASET COMPOSITION:\n")
            f.write("-" * 30 + "\n")
            f.write(f"Total dispositivos: {total_devices}\n")
            f.write(f"Specimens Ãºnicos: {specimens}\n")
            
            if len(damage_dist) > 0:
                f.write("\nDistribuciÃ³n de daÃ±o (NIVEL DISPOSITIVO):\n")
                for damage_level, count in damage_dist.items():
                    percentage = (count / total_devices) * 100 if total_devices > 0 else 0
                    f.write(f"  {damage_level}: {count} dispositivos ({percentage:.1f}%)\n")
            
            f.write("\n" + "=" * 60 + "\n")
            f.write("VENTAJAS METODOLÃ“GICAS CRÃTICAS\n")
            f.write("=" * 60 + "\n")
            f.write("ğŸ¯ RESOLUCIÃ“N DE PROBLEMAS FUNDAMENTALES:\n")
            f.write("  âŒ Exp1-3: Bins FFT como observaciones â†’ Pseudo-replicaciÃ³n\n")
            f.write("  âœ… Exp4: Dispositivos como observaciones â†’ MetodolÃ³gicamente correcto\n\n")
            f.write("  âŒ Exp1-3: Miles de 'observaciones' del mismo dispositivo\n") 
            f.write("  âœ… Exp4: Una observaciÃ³n por dispositivo fÃ­sico\n\n")
            f.write("  âŒ Exp1-3: Unidad observaciÃ³n â‰  Unidad inferencia\n")
            f.write("  âœ… Exp4: AlineaciÃ³n perfecta de unidades\n\n")
            
            f.write("ğŸ”¬ VALIDEZ CIENTÃFICA:\n")
            f.write("  âœ… MetodologÃ­a estadÃ­sticamente vÃ¡lida\n")
            f.write("  âœ… Resultados interpretables y aplicables\n")
            f.write("  âœ… Sin inflaciÃ³n artificial de mÃ©tricas\n")
            f.write("  âœ… EvaluaciÃ³n realista de capacidad predictiva\n\n")
            
            f.write("=" * 80 + "\n")
            f.write("CONCLUSIÃ“N METODOLÃ“GICA\n")
            f.write("=" * 80 + "\n")
            f.write("Este enfoque (Exp4) representa la implementaciÃ³n metodolÃ³gicamente\n")
            f.write("correcta para machine learning en detecciÃ³n de daÃ±os estructurales.\n")
            f.write("Los resultados de este experimento serÃ¡n cientÃ­ficamente vÃ¡lidos\n")
            f.write("y aplicables en la prÃ¡ctica real.\n\n")
            f.write("=" * 80 + "\n")
            f.write("END OF SUMMARY\n")
            f.write("=" * 80 + "\n")
        
        print("\n" + "="*80)
        print("ğŸ‰ PREPROCESAMIENTO METODOLÃ“GICAMENTE CORRECTO COMPLETADO")
        print("="*80)
        print(f"ğŸ“Š Dataset generado: {output_path}")
        print(f"ğŸ“‹ Resumen: {summary_path}")
        print(f"â±ï¸ Tiempo total: {processing_time + export_time:.1f} segundos")
        print()
        print("ğŸ”¬ ENFOQUE METODOLÃ“GICAMENTE CORRECTO IMPLEMENTADO:")
        print("   âœ… Una observaciÃ³n = Un dispositivo fÃ­sico completo")
        print("   âœ… CaracterÃ­sticas estadÃ­sticas agregadas")
        print("   âœ… PrevenciÃ³n total de pseudo-replicaciÃ³n")
        print("   âœ… AlineaciÃ³n correcta: Unidad observaciÃ³n = Unidad inferencia")
        print("   âœ… MetodologÃ­a cientÃ­ficamente vÃ¡lida")
        print(f"   âœ… {total_devices} dispositivos procesados correctamente")
        print()
        print("ğŸ¯ RESULTADO: Dataset listo para ML metodolÃ³gicamente correcto")
        
        return 0
        
    except Exception as e:
        print(f"âŒ Error durante el preprocesamiento: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())