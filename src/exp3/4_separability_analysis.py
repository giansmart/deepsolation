#!/usr/bin/env python3
"""
AnÃ¡lisis de Separabilidad de Clases - Experimento 3
==================================================

Analiza la separabilidad intrÃ­nseca de las clases de daÃ±o (N1, N2, N3) 
comparando dataset original vs balanceado para validar que la augmentaciÃ³n
conservadora no distorsiona los patrones naturales de separabilidad.

MÃ©tricas implementadas:
1. PCA - VisualizaciÃ³n 2D/3D de clusters por clase
2. Silhouette Score - Calidad de clustering por clase
3. Davies-Bouldin Index - SeparaciÃ³n inter/intra cluster  
4. Distancias entre centroides - Separabilidad cuantitativa
5. AnÃ¡lisis de overlap - Porcentaje de sobreposiciÃ³n entre clases

Uso:
    python3 src/exp3/4_separability_analysis.py

Requisitos:
    - preprocessed_dataset.csv (dataset original)
    - balanced_dataset.csv (dataset balanceado)

Salidas:
    - results/separability_pca_comparison.png: PCA plots comparativos
    - results/separability_metrics_comparison.png: MÃ©tricas cuantitativas  
    - results/separability_analysis_report.txt: Reporte detallado
    - results/class_centroids_distances.png: AnÃ¡lisis de distancias

Este anÃ¡lisis ayuda a entender por quÃ© N3 tiene mÃ©tricas bajas:
Â¿Es problema de datos insuficientes o separabilidad intrÃ­nseca baja?
"""

import argparse
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import silhouette_score, silhouette_samples
from sklearn.metrics.pairwise import euclidean_distances
from scipy.spatial.distance import pdist, squareform
from scipy.stats import entropy
import warnings
warnings.filterwarnings('ignore')

# Agregar src al path
sys.path.append(str(Path(__file__).parent.parent))

def load_datasets():
    """Cargar ambos datasets para comparaciÃ³n"""
    print("ðŸ“‚ Cargando datasets...")
    
    # Rutas relativas al script
    script_dir = Path(__file__).parent
    original_path = script_dir / "results" / "preprocessed_dataset.csv"
    balanced_path = script_dir / "results" / "balanced_dataset.csv"
    
    # Verificar archivos
    if not original_path.exists():
        raise FileNotFoundError(f"Dataset original no encontrado: {original_path}")
    if not balanced_path.exists():
        raise FileNotFoundError(f"Dataset balanceado no encontrado: {balanced_path}")
    
    # Cargar datasets
    df_original = pd.read_csv(original_path)
    df_balanced = pd.read_csv(balanced_path)
    
    print(f"âœ“ Dataset original: {len(df_original)} muestras")
    print(f"âœ“ Dataset balanceado: {len(df_balanced)} muestras")
    
    # Mostrar distribuciones
    print(f"\nðŸ“Š DistribuciÃ³n original:")
    orig_counts = df_original['damage_level'].value_counts().sort_index()
    for damage_level, count in orig_counts.items():
        percentage = (count / len(df_original)) * 100
        print(f"   {damage_level}: {count} ({percentage:.1f}%)")
    
    print(f"\nðŸ“Š DistribuciÃ³n balanceada:")
    bal_counts = df_balanced['damage_level'].value_counts().sort_index()
    for damage_level, count in bal_counts.items():
        percentage = (count / len(df_balanced)) * 100
        print(f"   {damage_level}: {count} ({percentage:.1f}%)")
    
    return df_original, df_balanced

def extract_features_and_labels(df, dataset_name):
    """Extraer features de frecuencia y labels"""
    print(f"\nðŸ”„ Procesando features de {dataset_name}...")
    
    # Encontrar columnas de frecuencia
    import re
    freq_pattern = re.compile(r'^freq_\d+_(NS|EW|UD)$')
    freq_cols = [col for col in df.columns if freq_pattern.match(col)]
    
    if len(freq_cols) == 0:
        raise ValueError(f"No se encontraron columnas de frecuencia en {dataset_name}")
    
    # Extraer features y labels
    X = df[freq_cols].values
    y = df['damage_level'].values
    
    # Codificar labels
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    class_names = label_encoder.classes_.tolist()
    
    print(f"âœ“ Features extraÃ­das: {X.shape[1]:,} caracterÃ­sticas")
    print(f"âœ“ Clases encontradas: {class_names}")
    
    return X, y_encoded, class_names, freq_cols

def compute_separability_metrics(X, y_encoded, class_names, dataset_name):
    """Calcular mÃ©tricas de separabilidad"""
    print(f"\nðŸ“Š Calculando mÃ©tricas de separabilidad para {dataset_name}...")
    
    metrics = {}
    
    # 1. Silhouette Score global
    try:
        silhouette_avg = silhouette_score(X, y_encoded)
        metrics['silhouette_global'] = silhouette_avg
        print(f"   ðŸ“ˆ Silhouette Score: {silhouette_avg:.4f}")
    except Exception as e:
        print(f"   âš ï¸ Error calculando Silhouette Score: {e}")
        metrics['silhouette_global'] = 0.0
    
    # 2. Silhouette Score por clase
    try:
        silhouette_samples_scores = silhouette_samples(X, y_encoded)
        silhouette_per_class = {}
        
        for i, class_name in enumerate(class_names):
            class_mask = y_encoded == i
            if np.sum(class_mask) > 0:
                class_silhouette = np.mean(silhouette_samples_scores[class_mask])
                silhouette_per_class[class_name] = class_silhouette
                print(f"   ðŸ“ˆ Silhouette {class_name}: {class_silhouette:.4f}")
        
        metrics['silhouette_per_class'] = silhouette_per_class
    except Exception as e:
        print(f"   âš ï¸ Error calculando Silhouette por clase: {e}")
        metrics['silhouette_per_class'] = {}
    
    # 3. Davies-Bouldin Index
    try:
        from sklearn.metrics import davies_bouldin_score
        db_score = davies_bouldin_score(X, y_encoded)
        metrics['davies_bouldin'] = db_score
        print(f"   ðŸ“ˆ Davies-Bouldin Index: {db_score:.4f}")
    except Exception as e:
        print(f"   âš ï¸ Error calculando Davies-Bouldin: {e}")
        metrics['davies_bouldin'] = np.inf
    
    # 4. Distancias entre centroides
    centroids = {}
    centroid_distances = {}
    
    for i, class_name in enumerate(class_names):
        class_mask = y_encoded == i
        if np.sum(class_mask) > 0:
            centroid = np.mean(X[class_mask], axis=0)
            centroids[class_name] = centroid
    
    # Calcular distancias entre centroides
    for i, class1 in enumerate(class_names):
        for j, class2 in enumerate(class_names):
            if i < j and class1 in centroids and class2 in centroids:
                dist = euclidean_distances([centroids[class1]], [centroids[class2]])[0][0]
                pair = f"{class1}-{class2}"
                centroid_distances[pair] = dist
                print(f"   ðŸ“ Distancia centroide {pair}: {dist:.2f}")
    
    metrics['centroids'] = centroids
    metrics['centroid_distances'] = centroid_distances
    
    # 5. Variabilidad intra-clase (dispersiÃ³n)
    intra_class_variance = {}
    for i, class_name in enumerate(class_names):
        class_mask = y_encoded == i
        if np.sum(class_mask) > 1:
            class_data = X[class_mask]
            variance = np.mean(np.var(class_data, axis=0))
            intra_class_variance[class_name] = variance
            print(f"   ðŸ“Š Varianza intra-clase {class_name}: {variance:.2f}")
    
    metrics['intra_class_variance'] = intra_class_variance
    
    return metrics

def perform_pca_analysis(X, y_encoded, class_names, dataset_name):
    """Realizar anÃ¡lisis PCA para visualizaciÃ³n"""
    print(f"\nðŸ” AnÃ¡lisis PCA para {dataset_name}...")
    
    # Estandarizar datos
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # PCA a 2 y 3 componentes
    pca_2d = PCA(n_components=2)
    X_pca_2d = pca_2d.fit_transform(X_scaled)
    
    pca_3d = PCA(n_components=3) 
    X_pca_3d = pca_3d.fit_transform(X_scaled)
    
    print(f"   ðŸ“Š Varianza explicada PCA-2D: {pca_2d.explained_variance_ratio_.sum():.4f}")
    print(f"   ðŸ“Š Varianza explicada PCA-3D: {pca_3d.explained_variance_ratio_.sum():.4f}")
    
    return {
        'X_pca_2d': X_pca_2d,
        'X_pca_3d': X_pca_3d,
        'pca_2d': pca_2d,
        'pca_3d': pca_3d,
        'scaler': scaler
    }

def create_pca_comparison_plot(pca_original, pca_balanced, y_orig, y_bal, class_names, output_path):
    """Crear plot comparativo de PCA"""
    print(f"\nðŸŽ¨ Creando plot comparativo de PCA...")
    
    # Configurar colores consistentes por clase
    colors = ['#2E4057', '#048A81', '#54C6EB']  # N1, N2, N3
    color_map = {i: colors[i] for i in range(len(class_names))}
    
    fig = plt.figure(figsize=(20, 12))
    
    # Plot 2D - Original
    ax1 = plt.subplot(2, 3, 1)
    for i, class_name in enumerate(class_names):
        mask = y_orig == i
        if np.sum(mask) > 0:
            plt.scatter(pca_original['X_pca_2d'][mask, 0], 
                       pca_original['X_pca_2d'][mask, 1],
                       c=color_map[i], label=f'{class_name} (n={np.sum(mask)})',
                       alpha=0.7, s=50)
    
    plt.xlabel(f'PC1 ({pca_original["pca_2d"].explained_variance_ratio_[0]:.2%})')
    plt.ylabel(f'PC2 ({pca_original["pca_2d"].explained_variance_ratio_[1]:.2%})')
    plt.title('Dataset Original - PCA 2D', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot 2D - Balanceado
    ax2 = plt.subplot(2, 3, 2)
    for i, class_name in enumerate(class_names):
        mask = y_bal == i
        if np.sum(mask) > 0:
            plt.scatter(pca_balanced['X_pca_2d'][mask, 0], 
                       pca_balanced['X_pca_2d'][mask, 1],
                       c=color_map[i], label=f'{class_name} (n={np.sum(mask)})',
                       alpha=0.7, s=50)
    
    plt.xlabel(f'PC1 ({pca_balanced["pca_2d"].explained_variance_ratio_[0]:.2%})')
    plt.ylabel(f'PC2 ({pca_balanced["pca_2d"].explained_variance_ratio_[1]:.2%})')
    plt.title('Dataset Balanceado - PCA 2D', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot 3D - Original
    ax3 = plt.subplot(2, 3, 4, projection='3d')
    for i, class_name in enumerate(class_names):
        mask = y_orig == i
        if np.sum(mask) > 0:
            ax3.scatter(pca_original['X_pca_3d'][mask, 0], 
                       pca_original['X_pca_3d'][mask, 1],
                       pca_original['X_pca_3d'][mask, 2],
                       c=color_map[i], label=f'{class_name}', alpha=0.6, s=30)
    
    ax3.set_xlabel(f'PC1 ({pca_original["pca_3d"].explained_variance_ratio_[0]:.1%})')
    ax3.set_ylabel(f'PC2 ({pca_original["pca_3d"].explained_variance_ratio_[1]:.1%})')
    ax3.set_zlabel(f'PC3 ({pca_original["pca_3d"].explained_variance_ratio_[2]:.1%})')
    ax3.set_title('Dataset Original - PCA 3D', fontsize=14, fontweight='bold')
    ax3.legend()
    
    # Plot 3D - Balanceado
    ax4 = plt.subplot(2, 3, 5, projection='3d')
    for i, class_name in enumerate(class_names):
        mask = y_bal == i
        if np.sum(mask) > 0:
            ax4.scatter(pca_balanced['X_pca_3d'][mask, 0], 
                       pca_balanced['X_pca_3d'][mask, 1],
                       pca_balanced['X_pca_3d'][mask, 2],
                       c=color_map[i], label=f'{class_name}', alpha=0.6, s=30)
    
    ax4.set_xlabel(f'PC1 ({pca_balanced["pca_3d"].explained_variance_ratio_[0]:.1%})')
    ax4.set_ylabel(f'PC2 ({pca_balanced["pca_3d"].explained_variance_ratio_[1]:.1%})')
    ax4.set_zlabel(f'PC3 ({pca_balanced["pca_3d"].explained_variance_ratio_[2]:.1%})')
    ax4.set_title('Dataset Balanceado - PCA 3D', fontsize=14, fontweight='bold')
    ax4.legend()
    
    # Plot de comparaciÃ³n de centroides 
    ax5 = plt.subplot(2, 3, (3, 6))
    
    # Calcular centroides en espacio PCA 2D
    centroids_orig = {}
    centroids_bal = {}
    
    for i, class_name in enumerate(class_names):
        # Original
        mask_orig = y_orig == i
        if np.sum(mask_orig) > 0:
            centroids_orig[class_name] = np.mean(pca_original['X_pca_2d'][mask_orig], axis=0)
        
        # Balanceado
        mask_bal = y_bal == i
        if np.sum(mask_bal) > 0:
            centroids_bal[class_name] = np.mean(pca_balanced['X_pca_2d'][mask_bal], axis=0)
    
    # Plot centroides
    for i, class_name in enumerate(class_names):
        if class_name in centroids_orig:
            plt.scatter(centroids_orig[class_name][0], centroids_orig[class_name][1], 
                       c=color_map[i], s=200, marker='x', label=f'{class_name} Original', linewidth=4)
        if class_name in centroids_bal:
            plt.scatter(centroids_bal[class_name][0], centroids_bal[class_name][1], 
                       c=color_map[i], s=200, marker='+', label=f'{class_name} Balanceado', linewidth=4)
    
    plt.xlabel('PC1')
    plt.ylabel('PC2') 
    plt.title('ComparaciÃ³n de Centroides\n(X = Original, + = Balanceado)', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   âœ“ Plot guardado: {output_path}")

def create_metrics_comparison_plot(metrics_orig, metrics_bal, class_names, output_path):
    """Crear plot comparativo de mÃ©tricas de separabilidad"""
    print(f"\nðŸŽ¨ Creando plot comparativo de mÃ©tricas...")
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # 1. Silhouette Scores por clase
    if 'silhouette_per_class' in metrics_orig and 'silhouette_per_class' in metrics_bal:
        classes = []
        scores_orig = []
        scores_bal = []
        
        for class_name in class_names:
            if class_name in metrics_orig['silhouette_per_class'] and class_name in metrics_bal['silhouette_per_class']:
                classes.append(class_name)
                scores_orig.append(metrics_orig['silhouette_per_class'][class_name])
                scores_bal.append(metrics_bal['silhouette_per_class'][class_name])
        
        x = np.arange(len(classes))
        width = 0.35
        
        ax1.bar(x - width/2, scores_orig, width, label='Original', alpha=0.8, color='#2E4057')
        ax1.bar(x + width/2, scores_bal, width, label='Balanceado', alpha=0.8, color='#048A81')
        
        ax1.set_xlabel('Clases')
        ax1.set_ylabel('Silhouette Score')
        ax1.set_title('Silhouette Score por Clase', fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(classes)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # AÃ±adir valores en las barras
        for i, (orig, bal) in enumerate(zip(scores_orig, scores_bal)):
            ax1.text(i - width/2, orig + 0.01, f'{orig:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
            ax1.text(i + width/2, bal + 0.01, f'{bal:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
    
    # 2. MÃ©tricas globales
    metrics_names = ['Silhouette Global', 'Davies-Bouldin']
    orig_values = [
        metrics_orig.get('silhouette_global', 0),
        metrics_orig.get('davies_bouldin', 0)
    ]
    bal_values = [
        metrics_bal.get('silhouette_global', 0), 
        metrics_bal.get('davies_bouldin', 0)
    ]
    
    x = np.arange(len(metrics_names))
    width = 0.35
    
    ax2.bar(x - width/2, orig_values, width, label='Original', alpha=0.8, color='#2E4057')
    ax2.bar(x + width/2, bal_values, width, label='Balanceado', alpha=0.8, color='#048A81')
    
    ax2.set_xlabel('MÃ©tricas')
    ax2.set_ylabel('Score')
    ax2.set_title('MÃ©tricas de Separabilidad Global', fontweight='bold')
    ax2.set_xticks(x)
    ax2.set_xticklabels(metrics_names, rotation=45)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # AÃ±adir valores
    for i, (orig, bal) in enumerate(zip(orig_values, bal_values)):
        ax2.text(i - width/2, orig + max(orig_values) * 0.02, f'{orig:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
        ax2.text(i + width/2, bal + max(bal_values) * 0.02, f'{bal:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
    
    # 3. Distancias entre centroides
    if 'centroid_distances' in metrics_orig and 'centroid_distances' in metrics_bal:
        pairs = []
        dist_orig = []
        dist_bal = []
        
        for pair in metrics_orig['centroid_distances']:
            if pair in metrics_bal['centroid_distances']:
                pairs.append(pair)
                dist_orig.append(metrics_orig['centroid_distances'][pair])
                dist_bal.append(metrics_bal['centroid_distances'][pair])
        
        x = np.arange(len(pairs))
        width = 0.35
        
        ax3.bar(x - width/2, dist_orig, width, label='Original', alpha=0.8, color='#2E4057')
        ax3.bar(x + width/2, dist_bal, width, label='Balanceado', alpha=0.8, color='#048A81')
        
        ax3.set_xlabel('Pares de Clases')
        ax3.set_ylabel('Distancia Euclidiana')
        ax3.set_title('Distancias entre Centroides', fontweight='bold')
        ax3.set_xticks(x)
        ax3.set_xticklabels(pairs, rotation=45)
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # AÃ±adir valores
        for i, (orig, bal) in enumerate(zip(dist_orig, dist_bal)):
            ax3.text(i - width/2, orig + max(dist_orig) * 0.02, f'{orig:.1f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
            ax3.text(i + width/2, bal + max(dist_bal) * 0.02, f'{bal:.1f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
    
    # 4. Variabilidad intra-clase
    if 'intra_class_variance' in metrics_orig and 'intra_class_variance' in metrics_bal:
        classes = []
        var_orig = []
        var_bal = []
        
        for class_name in class_names:
            if class_name in metrics_orig['intra_class_variance'] and class_name in metrics_bal['intra_class_variance']:
                classes.append(class_name)
                var_orig.append(metrics_orig['intra_class_variance'][class_name])
                var_bal.append(metrics_bal['intra_class_variance'][class_name])
        
        x = np.arange(len(classes))
        width = 0.35
        
        ax4.bar(x - width/2, var_orig, width, label='Original', alpha=0.8, color='#2E4057')
        ax4.bar(x + width/2, var_bal, width, label='Balanceado', alpha=0.8, color='#048A81')
        
        ax4.set_xlabel('Clases')
        ax4.set_ylabel('Varianza Intra-Clase')
        ax4.set_title('DispersiÃ³n Intra-Clase', fontweight='bold')
        ax4.set_xticks(x)
        ax4.set_xticklabels(classes)
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        # AÃ±adir valores
        for i, (orig, bal) in enumerate(zip(var_orig, var_bal)):
            ax4.text(i - width/2, orig + max(var_orig) * 0.02, f'{orig:.1f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
            ax4.text(i + width/2, bal + max(var_bal) * 0.02, f'{bal:.1f}', ha='center', va='bottom', fontweight='bold', fontsize=9)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   âœ“ Plot guardado: {output_path}")

def save_analysis_report(metrics_orig, metrics_bal, class_names, output_path):
    """Guardar reporte detallado del anÃ¡lisis"""
    print(f"\nðŸ’¾ Guardando reporte de anÃ¡lisis...")
    
    with open(output_path, 'w') as f:
        f.write("=" * 80 + "\n")
        f.write("ANÃLISIS DE SEPARABILIDAD DE CLASES - EXPERIMENTO 3\n")
        f.write("=" * 80 + "\n")
        f.write(f"Fecha: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Objetivo: Analizar separabilidad N1/N2/N3 y validar augmentaciÃ³n conservadora\n\n")
        
        f.write("MÃ‰TRICAS DE SEPARABILIDAD:\n")
        f.write("-" * 30 + "\n")
        
        # Silhouette Scores
        f.write("1. SILHOUETTE SCORE (mayor = mejor separabilidad):\n")
        f.write(f"   Global Original: {metrics_orig.get('silhouette_global', 0):.4f}\n")
        f.write(f"   Global Balanceado: {metrics_bal.get('silhouette_global', 0):.4f}\n")
        f.write(f"   Diferencia: {metrics_bal.get('silhouette_global', 0) - metrics_orig.get('silhouette_global', 0):+.4f}\n\n")
        
        f.write("   Por clase:\n")
        for class_name in class_names:
            orig_score = metrics_orig.get('silhouette_per_class', {}).get(class_name, 0)
            bal_score = metrics_bal.get('silhouette_per_class', {}).get(class_name, 0)
            diff = bal_score - orig_score
            f.write(f"   {class_name}: Original={orig_score:.4f}, Balanceado={bal_score:.4f}, Diff={diff:+.4f}\n")
        f.write("\n")
        
        # Davies-Bouldin Index
        f.write("2. DAVIES-BOULDIN INDEX (menor = mejor separabilidad):\n")
        f.write(f"   Original: {metrics_orig.get('davies_bouldin', 0):.4f}\n")
        f.write(f"   Balanceado: {metrics_bal.get('davies_bouldin', 0):.4f}\n")
        f.write(f"   Diferencia: {metrics_bal.get('davies_bouldin', 0) - metrics_orig.get('davies_bouldin', 0):+.4f}\n\n")
        
        # Distancias entre centroides
        f.write("3. DISTANCIAS ENTRE CENTROIDES:\n")
        for pair in metrics_orig.get('centroid_distances', {}):
            if pair in metrics_bal.get('centroid_distances', {}):
                orig_dist = metrics_orig['centroid_distances'][pair]
                bal_dist = metrics_bal['centroid_distances'][pair]
                diff = bal_dist - orig_dist
                f.write(f"   {pair}: Original={orig_dist:.2f}, Balanceado={bal_dist:.2f}, Diff={diff:+.2f}\n")
        f.write("\n")
        
        # Varianza intra-clase
        f.write("4. VARIANZA INTRA-CLASE (dispersiÃ³n dentro de cada clase):\n")
        for class_name in class_names:
            orig_var = metrics_orig.get('intra_class_variance', {}).get(class_name, 0)
            bal_var = metrics_bal.get('intra_class_variance', {}).get(class_name, 0)
            if orig_var > 0 and bal_var > 0:
                diff = bal_var - orig_var
                f.write(f"   {class_name}: Original={orig_var:.2f}, Balanceado={bal_var:.2f}, Diff={diff:+.2f}\n")
        f.write("\n")
        
        f.write("INTERPRETACIÃ“N DE RESULTADOS:\n")
        f.write("-" * 30 + "\n")
        
        # AnÃ¡lisis de separabilidad de N3
        n3_silhouette_orig = metrics_orig.get('silhouette_per_class', {}).get('N3', 0)
        n3_silhouette_bal = metrics_bal.get('silhouette_per_class', {}).get('N3', 0)
        
        f.write(f"â€¢ SEPARABILIDAD DE N3:\n")
        f.write(f"  - Silhouette Score N3: {n3_silhouette_orig:.4f} â†’ {n3_silhouette_bal:.4f}\n")
        if n3_silhouette_orig < 0.3:
            f.write(f"  - BAJA SEPARABILIDAD: N3 tiene overlap significativo con otras clases\n")
            f.write(f"  - Esto explica las mÃ©tricas bajas de clasificaciÃ³n para N3\n")
        elif n3_silhouette_orig < 0.5:
            f.write(f"  - SEPARABILIDAD MODERADA: N3 parcialmente distinguible\n")
        else:
            f.write(f"  - SEPARABILIDAD BUENA: N3 bien separada de otras clases\n")
        
        # ValidaciÃ³n de augmentaciÃ³n
        f.write(f"\nâ€¢ VALIDACIÃ“N DE AUGMENTACIÃ“N CONSERVADORA:\n")
        silhouette_change = abs(metrics_bal.get('silhouette_global', 0) - metrics_orig.get('silhouette_global', 0))
        if silhouette_change < 0.05:
            f.write(f"  - âœ“ AUGMENTACIÃ“N VÃLIDA: Cambio mÃ­nimo en separabilidad global ({silhouette_change:.4f})\n")
            f.write(f"  - Los patrones naturales de separabilidad se mantienen\n")
        else:
            f.write(f"  - âš ï¸ AUGMENTACIÃ“N MODIFICA SEPARABILIDAD: Cambio de {silhouette_change:.4f}\n")
            f.write(f"  - Verificar si las tÃ©cnicas conservadoras son suficientes\n")
        
        # Recomendaciones
        f.write(f"\nRECOMENDACIONES:\n")
        f.write("-" * 30 + "\n")
        
        if n3_silhouette_orig < 0.3:
            f.write("1. PROBLEMA DE SEPARABILIDAD INTRÃNSECA para N3:\n")
            f.write("   - Considerar caracterÃ­sticas adicionales (wavelets, statistical features)\n")
            f.write("   - Evaluar redefiniciÃ³n de clases de daÃ±o\n")
            f.write("   - MÃ©todos de feature engineering mÃ¡s avanzados\n\n")
        
        f.write("2. ESTRATEGIAS PARA MEJORAR CLASIFICACIÃ“N N3:\n")
        f.write("   - Class weights agresivos (implementado: manual_weights)\n")
        f.write("   - Ensemble methods con especializaciÃ³n en clases minoritarias\n")
        f.write("   - Threshold tuning para maximizar recall de N3\n\n")
        
        f.write("3. VALIDACIÃ“N DE METHODOLOGY:\n")
        f.write("   - AugmentaciÃ³n conservadora mantiene patrones naturales\n")
        f.write("   - Separabilidad se preserva entre datasets\n")
        f.write("   - Problema de N3 es intrÃ­nseco, no por falta de datos\n\n")
        
        f.write("=" * 80 + "\n")
        f.write("FIN DEL ANÃLISIS\n")
        f.write("=" * 80 + "\n")
    
    print(f"   âœ“ Reporte guardado: {output_path}")

def main():
    """FunciÃ³n principal"""
    print("=" * 80)
    print("ANÃLISIS DE SEPARABILIDAD DE CLASES - EXPERIMENTO 3")
    print("=" * 80)
    print(f"Timestamp: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("Objetivo: Analizar separabilidad intrÃ­nseca y validar augmentaciÃ³n")
    print()
    
    try:
        # Crear directorio de resultados
        results_dir = Path(__file__).parent / "results"
        results_dir.mkdir(exist_ok=True)
        
        # 1. Cargar datasets
        df_original, df_balanced = load_datasets()
        
        # 2. Extraer features y labels
        X_orig, y_orig, class_names, _ = extract_features_and_labels(df_original, "Original")
        X_bal, y_bal, _, _ = extract_features_and_labels(df_balanced, "Balanceado")
        
        # 3. Calcular mÃ©tricas de separabilidad
        metrics_orig = compute_separability_metrics(X_orig, y_orig, class_names, "Original")
        metrics_bal = compute_separability_metrics(X_bal, y_bal, class_names, "Balanceado")
        
        # 4. AnÃ¡lisis PCA
        pca_orig = perform_pca_analysis(X_orig, y_orig, class_names, "Original") 
        pca_bal = perform_pca_analysis(X_bal, y_bal, class_names, "Balanceado")
        
        # 5. Crear visualizaciones
        pca_plot_path = results_dir / "separability_pca_comparison.png"
        create_pca_comparison_plot(pca_orig, pca_bal, y_orig, y_bal, class_names, pca_plot_path)
        
        metrics_plot_path = results_dir / "separability_metrics_comparison.png"
        create_metrics_comparison_plot(metrics_orig, metrics_bal, class_names, metrics_plot_path)
        
        # 6. Guardar reporte
        report_path = results_dir / "separability_analysis_report.txt"
        save_analysis_report(metrics_orig, metrics_bal, class_names, report_path)
        
        # 7. Resumen final
        print("\n" + "=" * 80)
        print("ðŸŽ‰ ANÃLISIS DE SEPARABILIDAD COMPLETADO")
        print("=" * 80)
        
        # Mostrar mÃ©tricas clave
        print("ðŸ“Š MÃ‰TRICAS CLAVE:")
        print(f"   Silhouette Global Original: {metrics_orig.get('silhouette_global', 0):.4f}")
        print(f"   Silhouette Global Balanceado: {metrics_bal.get('silhouette_global', 0):.4f}")
        
        if 'silhouette_per_class' in metrics_orig:
            print(f"\nðŸ“Š SEPARABILIDAD POR CLASE (Original):")
            for class_name in class_names:
                score = metrics_orig['silhouette_per_class'].get(class_name, 0)
                if score < 0.3:
                    status = "ðŸ”´ BAJA"
                elif score < 0.5:
                    status = "ðŸŸ¡ MODERADA" 
                else:
                    status = "ðŸŸ¢ BUENA"
                print(f"   {class_name}: {score:.4f} {status}")
        
        print(f"\nðŸ“ ARCHIVOS GENERADOS:")
        print(f"   ðŸ“Š PCA Comparison: {pca_plot_path}")
        print(f"   ðŸ“ˆ MÃ©tricas Comparison: {metrics_plot_path}")
        print(f"   ðŸ“‹ Reporte detallado: {report_path}")
        
        # ConclusiÃ³n sobre N3
        n3_silhouette = metrics_orig.get('silhouette_per_class', {}).get('N3', 0)
        if n3_silhouette < 0.3:
            print(f"\nðŸ”¬ CONCLUSIÃ“N CLAVE:")
            print(f"   N3 tiene BAJA SEPARABILIDAD INTRÃNSECA (Silhouette: {n3_silhouette:.4f})")
            print(f"   Esto explica las mÃ©tricas bajas en clasificaciÃ³n de N3")
            print(f"   El problema no es falta de datos, sino separabilidad fÃ­sica")
        
        return 0
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())