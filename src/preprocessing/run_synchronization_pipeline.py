#!/usr/bin/env python
"""
Pipeline completo de sincronizaci√≥n de se√±ales S1-S2.

Este script ejecuta el pipeline end-to-end:
1. Detecci√≥n de offsets temporales
2. Aplicaci√≥n de correcciones
3. Validaci√≥n de resultados

Uso:
    python -m src.preprocessing.run_synchronization_pipeline
    python -m src.preprocessing.run_synchronization_pipeline --detect-only
    python -m src.preprocessing.run_synchronization_pipeline --correct-only

Autor: Giancarlo Po√©mape Lozano
Fecha: 2026-02-07
"""

import sys
from pathlib import Path

from .detect_timestamp_offsets import detect_offsets
from .apply_timestamp_correction import apply_corrections


def run_pipeline(
    signals_dir: str = 'data/Signals_Raw/',
    labels_csv: str = 'data/nivel_damage.csv',
    offsets_csv: str = 'data/processed/timestamp_offsets.csv',
    output_dir: str = 'data/processed/synchronized/',
    detect_only: bool = False,
    correct_only: bool = False
):
    """
    Ejecuta el pipeline completo de sincronizaci√≥n.

    Args:
        signals_dir: Directorio ra√≠z de se√±ales RAW
        labels_csv: CSV con etiquetas
        offsets_csv: CSV de offsets (salida de paso 1, entrada de paso 2)
        output_dir: Directorio de salida para se√±ales sincronizadas
        detect_only: Si True, solo ejecuta detecci√≥n
        correct_only: Si True, solo ejecuta correcci√≥n

    Returns:
        Dict con resultados del pipeline
    """
    results = {}

    # PASO 1: Detecci√≥n de offsets
    if not correct_only:
        print("\n" + "="*70)
        print("PASO 1: DETECCI√ìN DE OFFSETS TEMPORALES")
        print("="*70 + "\n")

        offsets_df = detect_offsets(
            signals_dir=signals_dir,
            labels_csv=labels_csv
        )

        # Guardar tabla de offsets
        offsets_path = Path(offsets_csv)
        offsets_path.parent.mkdir(parents=True, exist_ok=True)
        offsets_df.to_csv(offsets_path, index=False)

        results['offsets_detected'] = len(offsets_df)
        results['offsets_file'] = str(offsets_path)

        print(f"\n‚úÖ Tabla de offsets guardada en: {offsets_path}")
        print(f"   {len(offsets_df)} registros escritos.\n")

        if detect_only:
            return results

    # PASO 2: Aplicaci√≥n de correcciones
    if not detect_only:
        print("\n" + "="*70)
        print("PASO 2: APLICACI√ìN DE CORRECCIONES")
        print("="*70 + "\n")

        stats = apply_corrections(
            signals_dir=signals_dir,
            offsets_csv=offsets_csv,
            output_dir=output_dir,
            method='shift_indices'
        )

        results['correction_stats'] = stats
        results['output_dir'] = output_dir

        print(f"\n‚úÖ Se√±ales sincronizadas guardadas en: {output_dir}")

    # Reporte final
    if not detect_only and not correct_only:
        print("\n" + "="*70)
        print("üìä REPORTE FINAL DEL PIPELINE")
        print("="*70)
        print(f"\n‚úÖ Pipeline completado exitosamente\n")

        print(f"   üìÇ Archivos generados:")
        print(f"      Tabla de offsets: {results['offsets_file']}")
        print(f"      Se√±ales sincronizadas: {results['output_dir']}\n")

        print(f"   üìà Estad√≠sticas:")
        print(f"      Total mediciones: {results['offsets_detected']}")
        print(f"      Se√±ales corregidas: {stats['corrected']}")
        print(f"      Ya sincronizadas: {stats['already_synced']}")
        print(f"      Errores: {len(stats['errors'])}\n")

        print(f"   üîç Validaci√≥n:")
        print(f"      Validaciones exitosas: {stats['validation_passed']}")
        print(f"      Validaciones fallidas: {stats['validation_failed']}")

        if stats['validation_failed'] > 0:
            total_val = stats['validation_passed'] + stats['validation_failed']
            pct_success = (stats['validation_passed'] / total_val) * 100
            print(f"      Tasa de √©xito: {pct_success:.1f}%")

        print("\n" + "="*70 + "\n")

        # Advertencias
        if len(stats['errors']) > 0:
            print("‚ö†Ô∏è  ADVERTENCIA: Se encontraron errores durante el procesamiento:")
            for error in stats['errors']:
                print(f"   - {error['specimen_id']}: {error['error']}")
            print()  # L√≠nea en blanco al final

        if stats['validation_failed'] > 0:
            print(f"‚ö†Ô∏è  ADVERTENCIA: {stats['validation_failed']} se√±ales con sincronizaci√≥n sub√≥ptima.")
            print("   Revisar archivos metadata.json en el directorio de salida.\n")

    return results


def main():
    """
    Funci√≥n principal para ejecuci√≥n desde l√≠nea de comandos.
    """
    import argparse

    parser = argparse.ArgumentParser(
        description='Pipeline completo de sincronizaci√≥n de se√±ales S1-S2',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos:
  # Ejecutar pipeline completo
  python scripts/run_synchronization_pipeline.py

  # Solo detectar offsets
  python scripts/run_synchronization_pipeline.py --detect-only

  # Solo aplicar correcciones (requiere que exista timestamp_offsets.csv)
  python scripts/run_synchronization_pipeline.py --correct-only

  # Especificar rutas personalizadas
  python scripts/run_synchronization_pipeline.py \\
      --signals-dir data/Signals_Raw/ \\
      --output-dir data/processed/synchronized_custom/
        """
    )

    parser.add_argument(
        '--signals-dir',
        default='data/Signals_Raw/',
        help='Directorio ra√≠z de se√±ales RAW'
    )
    parser.add_argument(
        '--labels-csv',
        default='data/nivel_damage.csv',
        help='CSV con etiquetas'
    )
    parser.add_argument(
        '--offsets-csv',
        default='data/processed/timestamp_offsets.csv',
        help='CSV de offsets'
    )
    parser.add_argument(
        '--output-dir',
        default='data/processed/synchronized/',
        help='Directorio de salida'
    )
    parser.add_argument(
        '--detect-only',
        action='store_true',
        help='Solo ejecutar detecci√≥n de offsets'
    )
    parser.add_argument(
        '--correct-only',
        action='store_true',
        help='Solo ejecutar correcci√≥n de se√±ales'
    )

    args = parser.parse_args()

    # Validar argumentos
    if args.detect_only and args.correct_only:
        parser.error("No se puede usar --detect-only y --correct-only simult√°neamente")

    # Ejecutar pipeline
    try:
        results = run_pipeline(
            signals_dir=args.signals_dir,
            labels_csv=args.labels_csv,
            offsets_csv=args.offsets_csv,
            output_dir=args.output_dir,
            detect_only=args.detect_only,
            correct_only=args.correct_only
        )

        print("‚úÖ Pipeline ejecutado exitosamente.\n")
        return 0

    except Exception as e:
        print(f"\n‚ùå ERROR: {str(e)}\n", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
