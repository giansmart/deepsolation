# Experimento 1: ImplementaciÃ³n Base Yu et al. (2018)

## ğŸ“‹ DescripciÃ³n

Este experimento implementa la metodologÃ­a base propuesta por Yu et al. (2018) para la identificaciÃ³n de daÃ±o en aisladores sÃ­smicos usando Deep Learning. El enfoque utiliza seÃ±ales de vibraciÃ³n ambiental procesadas mediante FFT y una red neuronal convolucional profunda (DCNN) para clasificar el nivel de daÃ±o estructural.

## ğŸ¯ Objetivos

- **Objetivo Principal**: Replicar y validar la metodologÃ­a Yu et al. (2018) en nuestro dataset de aisladores sÃ­smicos peruanos
- **Objetivos EspecÃ­ficos**:
  - Implementar pipeline de preprocesamiento FFT + PSD selection
  - Entrenar modelo DCNN para clasificaciÃ³n de niveles de daÃ±o (N0, N1, N2, N3)
  - Evaluar rendimiento usando mÃ©tricas estÃ¡ndar (accuracy, precision, recall, F1-score)
  - Establecer baseline para comparaciÃ³n con experimentos posteriores

## ğŸ”¬ MetodologÃ­a Yu et al. (2018)

### Pipeline de Procesamiento
1. **AdquisiciÃ³n de SeÃ±ales**: Vibraciones ambientales de 3 componentes (N-S, E-W, U-D)
2. **Preprocesamiento FFT**: Transformada rÃ¡pida de Fourier para obtener espectro de frecuencias
3. **SelecciÃ³n PSD**: SelecciÃ³n de componentes con >70% de energÃ­a
4. **Entrenamiento DCNN**: Red convolucional profunda para clasificaciÃ³n
5. **ValidaciÃ³n**: Train/Validation/Test split con mÃ©tricas de evaluaciÃ³n

### Arquitectura DCNN
- **Entrada**: Matriz de componentes de frecuencia Ã— sensores
- **Capas Convolucionales**: 3 capas con kernels adaptativos (100, 50, 25)
- **Pooling**: MaxPooling para reducciÃ³n dimensional
- **RegularizaciÃ³n**: BatchNorm + Dropout (30%)
- **ClasificaciÃ³n**: Capas densas + Softmax para 4 clases

## ğŸ“Š Pipeline Completo

```mermaid
flowchart TD
    A[SeÃ±ales Raw] --> B[1_preprocess_signals.py]
    B --> C[Dataset CSV]
    C --> D[2_balance_data.py]
    D --> E[Dataset Balanceado]
    E --> F[3_train_dcnn.py]
    F --> G[Modelo Entrenado]
    F --> H[MÃ©tricas de EvaluaciÃ³n]
    
    B --> B1[FFT Transform]
    B1 --> B2[PSD Selection 70%]
    B2 --> B3[Feature Matrix]
    
    D --> D1[SMOTE Oversampling]
    D1 --> D2[Synthetic Specimens]
    
    F --> F1[Train/Val/Test Split]
    F1 --> F2[DCNN Architecture]
    F2 --> F3[Training Loop]
    F3 --> F4[Best Model Selection]
    
    style A fill:#e1f5fe
    style G fill:#c8e6c9
    style H fill:#fff3e0
```

## ğŸ“ Estructura de Archivos

```
exp1/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ __init__.py                 # InicializaciÃ³n del mÃ³dulo
â”œâ”€â”€ 1_preprocess_signals.py     # Preprocesamiento de seÃ±ales
â”œâ”€â”€ 2_balance_data.py          # Balanceo del dataset con SMOTE
â”œâ”€â”€ 3_train_dcnn.py            # Entrenamiento del modelo DCNN
â”œâ”€â”€ dcnn_model.py              # Arquitectura del modelo PyTorch
â”œâ”€â”€ signal_preprocessing.py     # Utilidades de procesamiento FFT/PSD
â”œâ”€â”€ models/                     # Modelos entrenados
â”‚   â””â”€â”€ dcnn_model_*.pth
â””â”€â”€ results/                    # Resultados del experimento
    â”œâ”€â”€ preprocessed_dataset.csv
    â”œâ”€â”€ preprocessed_dataset_balanced.csv
    â”œâ”€â”€ training_history.png
    â””â”€â”€ evaluation_report.txt
```

## ğŸš€ Uso

### 1. Preprocesamiento de SeÃ±ales
```bash
python src/exp1/1_preprocess_signals.py
```

**Entrada**: `data/Signals_Raw/` (archivos .txt por specimen/sensor)
**Salida**: `src/exp1/results/preprocessed_dataset.csv`

### 2. Balanceo de Dataset (Opcional)
```bash
python src/exp1/2_balance_data.py --input src/exp1/results/preprocessed_dataset.csv
```

**Entrada**: Dataset procesado
**Salida**: `src/exp1/results/preprocessed_dataset_balanced.csv`

### 3. Entrenamiento DCNN
```bash
python src/exp1/3_train_dcnn.py --input src/exp1/results/preprocessed_dataset.csv
```

**Entrada**: Dataset procesado (balanceado o no)
**Salidas**: 
- `src/exp1/models/dcnn_model_*.pth` (modelo entrenado)
- `src/exp1/results/training_history.png` (curvas de entrenamiento)
- `src/exp1/results/evaluation_report.txt` (mÃ©tricas de evaluaciÃ³n)

## âš™ï¸ ConfiguraciÃ³n

### ParÃ¡metros de Preprocesamiento
- **Sampling Rate**: 100 Hz
- **Energy Threshold**: 70% para selecciÃ³n PSD
- **Componentes**: N-S, E-W, U-D

### ParÃ¡metros de Entrenamiento
- **Test Size**: 20%
- **Validation Size**: 20%
- **Batch Size**: 50
- **Learning Rate**: 0.0035
- **Epochs**: 100
- **Early Stopping**: Patience = 15
- **Dropout**: 30%

## ğŸ“ˆ MÃ©tricas de EvaluaciÃ³n

- **Accuracy**: PrecisiÃ³n general del modelo
- **Precision/Recall/F1**: Por clase (N0, N1, N2, N3)
- **Confusion Matrix**: Matriz de confusiÃ³n detallada
- **Loss Curves**: Training vs Validation loss

## âš ï¸ Limitaciones Identificadas

1. **Data Leakage Potencial**:
   - Split simple sin considerar correlaciÃ³n entre especÃ­menes del mismo aislador fÃ­sico
   - Preprocessing global antes de train/test split
   - Falta de validaciÃ³n cruzada grupal

2. **ValidaciÃ³n MetodolÃ³gica**:
   - Sin implementaciÃ³n de GroupKFold
   - ParÃ¡metros de normalizaciÃ³n calculados con todo el dataset
   - SelecciÃ³n de frecuencias PSD influenciada por datos de test

## ğŸ”„ Siguientes Experimentos

- **Exp2**: ImplementaciÃ³n con GroupKFold para prevenir data leakage
- **Exp3**: Preprocessing dentro de cross-validation
- **Exp4**: Arquitecturas alternativas (1D-CNN, transformers)
- **Exp5**: Ensemble methods y tÃ©cnicas avanzadas

## ğŸ“š Referencias

Yu, Y., Wang, C., Gu, X., & Li, J. (2018). A novel deep learning-based method for damage identification of smart building structures. *Computer-Aided Civil and Infrastructure Engineering*, 34(5), 416-430.

---

**Nota**: Este es el experimento baseline. Los resultados de este experimento pueden estar sobreestimados debido a las limitaciones metodolÃ³gicas identificadas. Los experimentos posteriores abordarÃ¡n estas limitaciones sistemÃ¡ticamente.