# ğŸ—ï¸ DeepIsolation - ClasificaciÃ³n de DaÃ±o en Aisladores SÃ­smicos

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto de tesis desarrolla un modelo de machine learning para **clasificar el nivel de daÃ±o** en aisladores sÃ­smicos mediante anÃ¡lisis de seÃ±ales de vibraciÃ³n. El sistema permite predecir automÃ¡ticamente el estado estructural de aisladores basÃ¡ndose en mediciones de aceleraciÃ³n en mÃºltiples ejes.

## ğŸ¯ Objetivos

- **Principal**: Desarrollar un modelo de clasificaciÃ³n que determine el nivel de daÃ±o (N1, N2, N3) en aisladores sÃ­smicos
- **Secundarios**:
  - Analizar seÃ±ales de vibraciÃ³n en tiempo real
  - Comparar enfoques de caracterÃ­sticas ingenieriles vs. deep learning
  - Implementar tÃ©cnicas de balanceado de clases
  - Validar robustez del modelo ante variabilidad experimental

## ğŸ“Š Estructura de Datos

### ğŸ­ **Aisladores y Experimentos**
- **15 aisladores Ãºnicos**: A1, A2, A3, ..., A15
- **MÃºltiples experimentos por aislador**: A1, A1-2, A1-3 (hasta 3 experimentos)
- **Total**: 2,234 registros experimentales

### ğŸ“ˆ **Niveles de DaÃ±o**
- **N1**: Sin daÃ±o (1,177 muestras - 52.7%)
- **N2**: DaÃ±o moderado (801 muestras - 35.9%)
- **N3**: DaÃ±o severo (256 muestras - 11.5%)
- **Desbalance**: Ratio 4.60:1 (N1:N3)

### ğŸ—‚ï¸ **Datasets Disponibles**

#### 1. **SeÃ±ales Crudas** (`data/Signals_Raw/`)
```
A1/
â”œâ”€â”€ completo_S1.txt  # Sensor sÃ³tano 1
â””â”€â”€ completo_S2.txt  # Sensor sÃ³tano 2

Formato:
Fecha Hora               N-S           E-W           U-D
2024/05/23 09:47:00.000  3.183131e-002 -3.726171e-002 -3.008206e-002
```
- **Frecuencia**: 100 Hz (muestras cada 0.010s)
- **Ejes**: N-S (Norte-Sur), E-W (Este-Oeste), U-D (Up-Down)
- **Sensores duales**: S1 y S2 en diferentes ubicaciones

#### 2. **Dataset Procesado** (`data/Arreglo_3_actual.csv`)
- **37 columnas**: 14 geomÃ©tricas + 20 caracterÃ­sticas de vibraciÃ³n + 3 etiquetas
- **CaracterÃ­sticas S1**: 10 caracterÃ­sticas calculadas del sensor S1
- **CaracterÃ­sticas S2**: 10 caracterÃ­sticas calculadas del sensor S2
- **Variables**: Spectral entropy, Power bandwidth, Median frequency, etc.

#### 3. **Dataset Completo** (`data/ARR3_DF_FINAL.xlsx`)
- **327 columnas**: AnÃ¡lisis exhaustivo con caracterÃ­sticas avanzadas
- **Procesamiento intensivo**: Transformadas, wavelets, MFCC, etc.

## âš ï¸ **Consideraciones CrÃ­ticas para Machine Learning**

### ğŸ”´ **Data Leakage Potencial**
**PROBLEMA**: MÃºltiples experimentos del mismo aislador pueden aparecer en train y test.

**Ejemplo problemÃ¡tico**:
```
Train: A1 â†’ N1     |  Test: A1-2 â†’ N1
```
El modelo aprende caracterÃ­sticas **del aislador especÃ­fico**, no del **tipo de daÃ±o**.

### âœ… **SoluciÃ³n: Split por Aislador**
```python
# âŒ Split incorrecto (por experimento)
train_test_split(X, y, test_size=0.2, random_state=42)

# âœ… Split correcto (por aislador)
isolators = ['A1', 'A2', 'A3', ..., 'A15']
train_isolators = ['A1', 'A3', 'A5', 'A7', 'A9', 'A11', 'A13', 'A15']
test_isolators = ['A2', 'A4', 'A6', 'A8', 'A10', 'A12', 'A14']
```

### ğŸ“Š **DesafÃ­os del Dataset**
1. **Pocos aisladores Ãºnicos**: Solo 15 (limitaciÃ³n para generalizaciÃ³n)
2. **Desbalance de clases**: N3 muy subrepresentado
3. **CorrelaciÃ³n intra-aislador**: Experimentos del mismo aislador son similares
4. **Variabilidad experimental**: Diferencias entre repeticiones

## ğŸš€ **Enfoques de Modelado**

### **Enfoque 1: CaracterÃ­sticas Ingenieriles**
- **Input**: Dataset procesado (34-327 variables)
- **Algoritmos**: Random Forest, SVM, XGBoost
- **Ventajas**: Interpretable, rÃ¡pido, caracterÃ­sticas fÃ­sicamente significativas
- **TÃ©cnicas**: SMOTE para balanceado, feature selection

### **Enfoque 2: Deep Learning en SeÃ±ales (Yu et al. 2018)**
- **Input**: SeÃ±ales crudas de vibraciÃ³n (FFT preprocessing)
- **Arquitectura**: DCNN (Deep Convolutional Neural Network)
- **MetodologÃ­a**: FFT â†’ PSD Selection â†’ DCNN Classification
- **Ventajas**: ExtracciÃ³n automÃ¡tica de caracterÃ­sticas, superior a GRNN/ANFIS
- **ImplementaciÃ³n**: PyTorch optimizado para Mac M2 Max (MPS)

## ğŸ“ Estructura del Proyecto

```
deepsolation/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Signals_Raw/           # SeÃ±ales originales por aislador
â”‚   â”œâ”€â”€ Arreglo_3_actual.csv   # Dataset simplificado (37 cols)
â”‚   â”œâ”€â”€ ARR3_DF_FINAL.xlsx     # Dataset completo (327 cols)
â”‚   â””â”€â”€ *.csv                  # Datasets procesados
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_exploration_df_final.ipynb      # AnÃ¡lisis dataset completo
â”‚   â”œâ”€â”€ 2_exploration_df_actual.ipynb     # AnÃ¡lisis dataset simplificado
â”‚   â”œâ”€â”€ 3_balancing.ipynb                 # TÃ©cnicas de oversampling
â”‚   â””â”€â”€ demo_signals.py                   # Demo PyTorch DCNN (Yu et al.)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ signal_preprocessing.py           # Pipeline FFT Yu et al.
â”‚   â””â”€â”€ dcnn_model_pytorch.py            # Modelo DCNN PyTorch
â””â”€â”€ docs/
    â”œâ”€â”€ ARR3_DF_FINAL_DataDictionary.xlsx
    â””â”€â”€ [documentaciÃ³n adicional]
```

## ğŸ› ï¸ InstalaciÃ³n y Uso

### Requisitos
```bash
pip install -r requirements.txt
```

### AnÃ¡lisis Exploratorio
1. **Dataset completo**: `notebooks/1_exploration_df_final.ipynb`
2. **Dataset simplificado**: `notebooks/2_exploration_df_actual.ipynb`
3. **Balanceado de clases**: `notebooks/3_balancing.ipynb`

## ğŸ“ˆ **PrÃ³ximos Pasos**

### **Fase 1: Baseline (En Progreso)**
- [x] AnÃ¡lisis exploratorio completo
- [x] ConversiÃ³n de formato one-hot
- [x] ImplementaciÃ³n SMOTE
- [ ] Modelado con caracterÃ­sticas ingenieriles
- [ ] ValidaciÃ³n con split por aislador

### **Fase 2: AnÃ¡lisis de SeÃ±ales**
- [ ] ExploraciÃ³n de seÃ±ales crudas
- [ ] VisualizaciÃ³n en tiempo y frecuencia  
- [ ] CorrelaciÃ³n entre sensores S1 y S2
- [ ] ExtracciÃ³n de nuevas caracterÃ­sticas

### **Fase 3: Deep Learning (Implementado)**
- [x] ImplementaciÃ³n metodologÃ­a Yu et al. (2018)
- [x] Pipeline FFT con selecciÃ³n PSD (70% energÃ­a)
- [x] Arquitectura DCNN con kernels adaptativos
- [x] OptimizaciÃ³n PyTorch para Mac M2 Max (MPS)
- [x] HiperparÃ¡metros Ã³ptimos (lr=0.0035, batch=50)
- [ ] ComparaciÃ³n con enfoques tradicionales
- [ ] AnÃ¡lisis de resultados y mÃ©tricas

## ğŸ§  **Pipeline DCNN - MetodologÃ­a Yu et al. (2018)**

### ğŸ“‹ **Resumen del MÃ©todo**
ImplementaciÃ³n completa de la metodologÃ­a **Yu et al. (2018)** para identificaciÃ³n automÃ¡tica de daÃ±o estructural usando Deep Convolutional Neural Networks (DCNN) aplicado a seÃ±ales de vibraciÃ³n.

### ğŸ”„ **Flujo del Pipeline**

```mermaid
graph TB
    A[ğŸ“Š SeÃ±ales Raw<br/>~60k muestras<br/>3 ejes N-S, E-W, U-D] --> B[ğŸ”§ FFT Transform<br/>Dominio tiempo â†’ frecuencia]
    B --> C[âš¡ Power Spectral Density<br/>CÃ¡lculo de energÃ­a por frecuencia]
    C --> D[ğŸ¯ SelecciÃ³n PSD<br/>Componentes con >70% energÃ­a]
    D --> E[ğŸ“¦ Matriz de CaracterÃ­sticas<br/>Frecuencias Ã— Sensores]
    E --> F[ğŸ§  DCNN Architecture<br/>Kernels adaptativos]
    F --> G[ğŸ“ˆ ClasificaciÃ³n<br/>N1, N2, N3]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#f1f8e9
    style E fill:#fce4ec
    style F fill:#e8f5e8
    style G fill:#fff8e1
```

### ğŸ—ï¸ **Arquitectura DCNN**

```mermaid
graph LR
    A[Input<br/>Freq Ã— Sensors] --> B[Conv1D<br/>Kernel ~100<br/>128 channels]
    B --> C[BatchNorm<br/>+ ReLU<br/>+ MaxPool<br/>+ Dropout]
    C --> D[Conv1D<br/>Kernel 30<br/>256 channels]
    D --> E[BatchNorm<br/>+ ReLU<br/>+ MaxPool<br/>+ Dropout]
    E --> F[Conv1D<br/>Kernel 10<br/>512 channels]
    F --> G[BatchNorm<br/>+ ReLU<br/>+ MaxPool<br/>+ Dropout]
    G --> H[Flatten]
    H --> I[FC 1024<br/>+ BatchNorm<br/>+ ReLU<br/>+ Dropout]
    I --> J[FC 512<br/>+ BatchNorm<br/>+ ReLU<br/>+ Dropout]
    J --> K[Output<br/>3 classes<br/>LogSoftmax]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style D fill:#f3e5f5
    style F fill:#f3e5f5
    style I fill:#e8f5e8
    style J fill:#e8f5e8
    style K fill:#fff8e1
```

### ğŸš€ **EjecuciÃ³n del Demo**

#### **Paso 1: InstalaciÃ³n**
```bash
pip install -r requirements.txt
cd notebooks
```

#### **Paso 2: EjecuciÃ³n**
```bash
python demo_signals.py
```

### ğŸ“Š **Resultados Esperados**

#### **CompresiÃ³n de Datos**
- **Entrada**: ~60,000 muestras temporales
- **Salida**: ~200-500 componentes frecuenciales
- **CompresiÃ³n**: 95-99% reducciÃ³n manteniendo 70% energÃ­a
- **Ejemplo**:
  ```
  Original signal: ~60,000 samples
  Compressed to: 342 frequency components  
  Compression ratio: 0.285
  ```

#### **Rendimiento del Modelo**
- **Accuracy esperada**: 85-95%
- **ComparaciÃ³n con paper**:
  - Yu et al. reportÃ³: SCC = 0.9983
  - Nuestro DCNN: Test Accuracy comparable
- **Ventajas sobre mÃ©todos tradicionales**:
  - Superior a GRNN (0.9692)
  - Superior a ANFIS (0.9672)


### ğŸ“ˆ **MÃ©tricas y Salidas**

#### **Archivos Generados**
1. **Modelo entrenado**: `../models/dcnn_pytorch_model.pth`
2. **Curvas de entrenamiento**: `../results/pytorch_training_history.png`
3. **Mejor modelo**: `best_model.pth` (auto-guardado)

#### **Monitoreo en Tiempo Real**
```
Epoch  12: Train Loss: 0.2341, Train Acc: 91.23%, Val Loss: 0.1987, Val Acc: 93.45%
Epoch  13: Train Loss: 0.2156, Train Acc: 92.11%, Val Loss: 0.1823, Val Acc: 94.12%
```

#### **EvaluaciÃ³n Final**
- **Classification Report**: Precision, Recall, F1-Score por clase
- **Confusion Matrix**: Matriz de confusiÃ³n detallada
- **Test Accuracy**: MÃ©trica final de rendimiento

### âš™ï¸ **HiperparÃ¡metros Optimizados**
Siguiendo **exactamente** los parÃ¡metros reportados por Yu et al.:

| ParÃ¡metro | Valor | JustificaciÃ³n |
|-----------|--------|---------------|
| Learning Rate | 0.0035 | Ã“ptimo reportado en paper |
| Batch Size | 50 | Mejor rendimiento experimental |
| Early Stopping | 15 epochs | PrevenciÃ³n de overfitting |
| Energy Threshold | 70% | Balance compresiÃ³n/informaciÃ³n |
| Dropout Rate | 0.3 | RegularizaciÃ³n efectiva |

### ğŸ”§ **Componentes TÃ©cnicos**

#### **1. SignalPreprocessor** (`src/signal_preprocessing.py`)
- Carga seÃ±ales multi-eje (N-S, E-W, U-D)
- AplicaciÃ³n FFT con frecuencias positivas
- SelecciÃ³n PSD con umbral de energÃ­a
- ConstrucciÃ³n matriz caracterÃ­sticas

#### **2. DCNNDamageNet** (`src/dcnn_model_pytorch.py`)
- Arquitectura convolucional 1D adaptativa
- Kernels progresivos: grande â†’ mediano â†’ pequeÃ±o
- RegularizaciÃ³n completa (BatchNorm + Dropout)
- Compatibilidad MPS para Mac M2 Max

#### **3. Pipeline Completo** (`notebooks/demo_signals.py`)
- DemostraciÃ³n paso a paso
- IntegraciÃ³n seÃ±ales raw + etiquetas CSV
- Entrenamiento con validaciÃ³n
- EvaluaciÃ³n y comparaciÃ³n con paper

## âš–ï¸ **Consideraciones Ã‰ticas y Limitaciones**

- **AplicaciÃ³n**: Sistema de monitoreo preventivo, no sustituto de inspecciÃ³n profesional
- **Limitaciones**: ValidaciÃ³n con solo 15 aisladores Ãºnicos
- **GeneralizaciÃ³n**: Resultados especÃ­ficos al tipo de aisladores estudiados
- **Seguridad**: Modelo como apoyo a decisiones, no decisiÃ³n automÃ¡tica

## ğŸ¤ **Contribuciones**

Este proyecto forma parte de una tesis de maestrÃ­a enfocada en la aplicaciÃ³n de machine learning para el monitoreo estructural de infraestructura sÃ­smica.

---

**Autor**: [Tu Nombre]  
**InstituciÃ³n**: [Tu Universidad]  
**AÃ±o**: 2024